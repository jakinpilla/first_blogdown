<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.69.0" />


<title>SVM theory Part1 - My DataScience Blog</title>
<meta property="og:title" content="SVM theory Part1 - My DataScience Blog">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">Daniel Kim</a></li>
    
    <li><a href="https://github.com/jakinpilla">GitHub</a></li>
    
    <li><a href="https://twitter.com/jakinpilla">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">5 min read</span>
    

    <h1 class="article-title">SVM theory Part1</h1>

    
    <span class="article-date">2020-05-18</span>
    

    <div class="article-content">
      


<pre class="r"><code>library(e1071)
library(tidyverse)
library(plotly)</code></pre>
<p>Logistic Regression에서는 확률을 이용합니다. 바로 확률을 이용해서 Decision Boundary를 결정합니다. 그런데 Support Vector Machine은 확률을 이용하지 않습니다. 다른 방법으로 Decision Boudary를 설정합니다.</p>
<pre class="r"><code># create linear_plot_with_theta_delta() funcition
# theata means a slope and delta means a margin

# set seed
set.seed(2020)
n &lt;- 50  
df &lt;- data.frame(x1 = runif(n), x2 = runif(n))
  

linear_plot_with_theta_delta &lt;- function(theta, delta) {
  

  # Generate data frame with two uniformly distributed predictors lying between 0 and 1.
  # classify data points depending on location
  df$y &lt;- factor(ifelse(df$x2 - theta*df$x1 &lt; 0, 0, 1), 
                 levels = c(0, 1))
  
  # retain only those points that lie outside the margin
  df_1 &lt;- df[abs(theta*df$x1 - df$x2) &gt; delta, ]
  
  # build plot
  plot_theta_margins &lt;- ggplot(data = df_1, aes(x = x1, y = x2, color = y)) + geom_point() + 
    scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + 
    geom_abline(slope = theta, intercept = 0, color = &quot;green&quot;, size = 1.2)+
    geom_abline(slope = theta, intercept = delta, linetype = &quot;dashed&quot;) +
    geom_abline(slope = theta, intercept = -delta, linetype = &quot;dashed&quot;) +
    theme(legend.position = &quot;none&quot;)
    # ggtitle(paste0(&quot;slope=&quot;, as.character(theta), &quot; delta=&quot;, as.character(delta)))
  
  #&#39; display plot
  plot_theta_margins
  
}

linear_plot_with_theta_delta(1, .1) +
  theme_minimal()</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>linear_plot_with_theta_delta(1, .1) +
  geom_abline(intercept = -.1, slope = 1.2, color = &#39;blue&#39;, size = 1.2) +
  geom_abline(intercept = .1, slope = .8, color = &#39;red&#39;, size = 1.2) +
  theme_minimal()</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>위의 그림에서 파란 점은 목적변수가 Positive 즉 1인 경우이고 빨간 점은 반대로 목적변수가 Negative 즉 0인 겨우입니다. 2차원에서 데이터를 정확히 2개의 그룹으로 분류하는 선 즉 Decision Boudary들은 여러 경우가 있을 수 있습니다. 그 중 저는 3가지 경우, 즉 파란선, 빨간선 드리고 초록선을 그려보았습니다. 이 셋 모델 모두 데이터를 정확히 Positive와 Negative로 100퍼센트 분리합니다.</p>
<p>그련데 우리의 직관은 뭔가 자꾸만 초록색 선이 다른 두 개의 선보다 더 훌륭한 Decision Boudary라고 하는 것 같습니다. 왠지 그렇지 않나요? 먼저 빨간색 Decision Boundary만 놓고 생각해 볼까요?</p>
<pre class="r"><code>df$y &lt;- factor(ifelse(df$x2 - 1*df$x1 &lt; 0, 0, 1), 
                 levels = c(0, 1))
df_1 &lt;- df[abs(1*df$x1 - df$x2) &gt; .1, ]

df_1 %&gt;%
  filter(y == 0) %&gt;%
  filter(x1 &gt; .75) %&gt;%
  filter(x2 &gt; .625 &amp; x2 &lt; .875) -&gt; df_tmp_1

df_1 %&gt;%
  filter(y == 1) %&gt;%
  filter(x1 &lt; .25) %&gt;%
  filter(x2 &gt; .1 &amp; x2 &lt; .375) -&gt; df_tmp_2


df_tmp_1 %&gt;%
  bind_rows(df_tmp_2) -&gt; df_2

linear_plot_with_theta_delta(1, .1) +
  geom_abline(intercept = .1, slope = .8, color = &#39;red&#39;, size = 1.2) +
  geom_point(data = df_2, aes(x1, x2), size = 7, alpha = .5, color = &#39;purple&#39;) +
  theme_minimal() -&gt; p; p</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>빨간선의 경우 그림에서처럼 4개의 보라색 원으로 감싸여진 데이터가 매우 Decision Boundary와 가까워집니다. 데이터라는 것은 언제나 특정 시점의 관측자에 의해 측정되어진 것이기에 그 값은 측정 시점과 관측자의 상태에 따라 변동이 생깁니다. 만약 위의 보라색 원 안에 있는 데이터들이 상하좌우로 이동을 하게 된다면 어떨까요? 어떤 경우는 Decision Boundary를 넘어가 Positive를 Negative로 혹은 Negative를 Positive로 잘못 분류하는 경우가 발생합니다. 즉, 빨간선을 Decision Boundary로 가지는 분류모델은 초록선을 Decision Boundary로 가지는 분류모델에 비해 불안한 나쁜 모델이라고 할 수 있습니다. 즉 우리의 직관이 맞는 겁니다.</p>
<p>그런데 어떻게 이 초록색 Decision Boundary를 잘 찾을 수 있을까요? 어떻게 이 Decision Boundary를 계산할 수 있을까요?</p>
<p>여기서 잠깐 한 Decision Boundary와 데이터들사이의 거리를 계산하는 문제를 생각해보겠습니다. 데이터에서 Decision Boudary로 수선의 발을 내려 그 거리를 재는 것입니다.</p>
<pre class="r"><code># the line&#39;s slope and intercept information
slope &lt;- 1
intercept &lt;- 0

perp.segment.coord &lt;- function(x1, x2, intercept, slope){
  # finds endpoint for a perpendicular segment from the point (x1,x2) to the line
  # defined by ortho as y = a*x + b
  a &lt;- slope  # slope
  b &lt;- intercept  # intercept
  xp1 &lt;- (x1 + a*x2 - a*b)/(1 + a^2)
  xp2 &lt;- b + a*xp1
  list(x1=x1, x2=x2, xp1=xp1, xp2=xp2)
}

perp.segment &lt;- perp.segment.coord(df_1$x1, df_1$x2, intercept, slope)
perp.segment_1 &lt;- perp.segment %&gt;% as.data.frame()
perp.segment_1 %&gt;%
  mutate(y = df_1$y) -&gt; perp.segment_2

ggplot(data = df_1, aes(x1, x2, color = y)) +
  geom_point() +
  scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;)) + 
  xlim(0, 1) +
  ylim(0, 1) +
  geom_abline(intercept = intercept, slope = slope) +
  geom_segment(data = perp.segment_2,
               aes(x = x1, y= x2, xend = xp1, yend = xp2), 
               lty = &#39;dashed&#39;) +
  theme_minimal() -&gt; p; p</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>y가 0이고 가장 가까운 거리를 가지는 점을 찾아보겠습니다.</p>
<pre class="r"><code>perp.segment_2 %&gt;%
  mutate(x_diff = xp1 - x1) %&gt;%
  mutate(y_diff = xp2 - x2) %&gt;%
  mutate(dist_sq = x_diff^2 + y_diff^2) %&gt;%
  mutate(dist_ucl = sqrt(dist_sq)) %&gt;%
  arrange(dist_sq) -&gt; df_with_dist

df_with_dist %&gt;%
  filter(y == 0) %&gt;%
  arrange(dist_sq) %&gt;%
  slice(1) %&gt;%
  select(x1, x2) -&gt; df_tmp

p + geom_point(data= df_tmp, 
               aes(x1, x2), size = 7, alpha = .5, color = &#39;purple&#39;)</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>바로 이 점을 지나고 Decisions Boudary와 평행한 직선을 그어보겠습니다. 이는 기울기가 1이고</p>
<pre class="r"><code>df_tmp</code></pre>
<pre><code>##          x1        x2
## 1 0.3942258 0.2882747</code></pre>
<p><code>x1 = 0.3942258</code>, <code>x2 = 0.2882747</code> 인 점을 지나는 직선을 찾는 문제가 됩니다.</p>
<pre><code>0.2882747 = 0.3942258 * 1 + intercept</code></pre>
<p>위의 식에서 intercept를 구하면 됩니다.</p>
<pre class="r"><code>0.2882747 - 0.3942258</code></pre>
<pre><code>## [1] -0.1059511</code></pre>
<p>즉, <code>intercept</code>는 <code>-0.1059511</code> 입니다. 시각화해보겠습니다.</p>
<pre class="r"><code> p_1 &lt;- p + 
  geom_point(data= df_tmp, aes(x1, x2), size = 7, alpha = .5, color = &#39;purple&#39;) + 
  geom_abline(intercept = -0.1059511, slope = 1, color = &#39;purple&#39;, size = 1, linetype = &#39;dashed&#39;); p_1</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>df_with_dist %&gt;%
  filter(y == 1) %&gt;%
  arrange(dist_sq) %&gt;%
  slice(1) %&gt;%
  select(x1, x2) -&gt; df_tmp

intercept &lt;- 0.6510358 - 0.5467153

p_1 + geom_point(data= df_tmp, 
               aes(x1, x2), size = 7, alpha = .5, color = &#39;purple&#39;) +
   geom_abline(intercept = intercept, slope = 1, color = &#39;purple&#39;, size = 1, linetype = &#39;dashed&#39;)</code></pre>
<p><img src="/post/2020-05-18-svm-theory-part1_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

