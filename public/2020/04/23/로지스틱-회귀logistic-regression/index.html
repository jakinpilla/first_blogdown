<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.69.0" />


<title>로지스틱 회귀(Logistic Regression) - My DataScience Blog</title>
<meta property="og:title" content="로지스틱 회귀(Logistic Regression) - My DataScience Blog">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">Daniel Kim</a></li>
    
    <li><a href="https://github.com/jakinpilla">GitHub</a></li>
    
    <li><a href="https://twitter.com/jakinpilla">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">22 min read</span>
    

    <h1 class="article-title">로지스틱 회귀(Logistic Regression)</h1>

    
    <span class="article-date">2020-04-23</span>
    

    <div class="article-content">
      
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/plotly-binding/plotly.js"></script>
<script src="/rmarkdown-libs/typedarray/typedarray.min.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<link href="/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plotly-main/plotly-latest.min.js"></script>


<div id="로지스틱-회귀란" class="section level2">
<h2>로지스틱 회귀란?</h2>
<p> 로지스틱 회귀는 결과변수가 범주형 변수이고 예측변수들이 연속변수 또는 범주형 변수인 회귀분석 모형입니다. 보통 머신러닝에서 분류(<strong>Classification</strong>)을 위해 가장 기본이 되는 모형으로 사용됩니다. 이 때 결과변수가 두 가지일(0 &amp; 1, False &amp; True, Neg &amp; Pos 등) 경우 <strong>Binary Logistic Regression</strong>라 하고, 결과변수가 셋 이상일 경우 <strong>Multinomial Logistic Regression</strong> 이라고 합니다.</p>
</div>
<div id="로지스틱-회귀의-원리" class="section level2">
<h2>로지스틱 회귀의 원리</h2>
<p> 예측변수가 <span class="math inline">\(X_{1i}\)</span> 하나 뿐인 가장 단순한 경우에, Y가 1이 될(혹은 True, Pos 등, 상대적으로 관심이 있어 예측을 하고 싶은 대상을 1로 둡니다.) <strong>확률</strong> <span class="math inline">\(P(Y = 1 | X_{1i})\)</span> 즉 <strong>관측값이 <span class="math inline">\(X_{1i}\)</span>일 때 예측값이 1이 될 확률</strong>을 구하기 위한 로지스틱 회귀 방정식은 다음과 같습니다.</p>
<p><span class="math display">\[P(Y=1 | X_{1i}) = \frac{1}{1 + e^{-(b_{0} + b_{1}X_{1i})}}\]</span></p>
<p>이 식을 변수 <span class="math inline">\(X_{1i}\)</span>에 대한 그래프로 그리면 다음과 같습니다.</p>
<pre class="r"><code>myfun &lt;- function(x_var) {1 / (1 + exp(-x_var))};
ggplot(data.frame(x= c(-10, 10)), aes(x=x)) + 
  stat_function(fun = myfun, geom=&quot;line&quot;, size = 1.2, color = &#39;steelblue&#39;) + 
  xlab(&quot;Z&quot;) +
  ylab(&quot;P(Y)&quot;) +
  theme_minimal() -&gt; p1; ggplotly(p1)</code></pre>
<div id="htmlwidget-1" style="width:576px;height:384px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"data":[{"x":[-10,-9.8,-9.6,-9.4,-9.2,-9,-8.8,-8.6,-8.4,-8.2,-8,-7.8,-7.6,-7.4,-7.2,-7,-6.8,-6.6,-6.4,-6.2,-6,-5.8,-5.6,-5.4,-5.2,-5,-4.8,-4.6,-4.4,-4.2,-4,-3.8,-3.6,-3.4,-3.2,-3,-2.8,-2.6,-2.4,-2.2,-2,-1.8,-1.6,-1.4,-1.2,-1,-0.799999999999999,-0.6,-0.399999999999999,-0.199999999999999,0,0.200000000000001,0.4,0.600000000000001,0.800000000000001,1,1.2,1.4,1.6,1.8,2,2.2,2.4,2.6,2.8,3,3.2,3.4,3.6,3.8,4,4.2,4.4,4.6,4.8,5,5.2,5.4,5.6,5.8,6,6.2,6.4,6.6,6.8,7,7.2,7.4,7.6,7.8,8,8.2,8.4,8.6,8.8,9,9.2,9.4,9.6,9.8,10],"y":[4.53978687024344e-005,5.54485247227949e-005,6.77241496197702e-005,8.27172228516664e-005,0.000101029193907773,0.000123394575986232,0.000150710358059757,0.000184071904963424,0.000224816770233295,0.000274578156101333,0.000335350130466478,0.00040956716498605,0.000500201107079564,0.000610879359434401,0.000746028833836698,0.000911051194400645,0.00111253603286032,0.00135851995042896,0.00165880108017442,0.00202532038904988,0.00247262315663477,0.00301841632470842,0.00368423989943599,0.00449627316094118,0.00548629889945041,0.00669285092428486,0.0081625711531599,0.00995180186690432,0.0121284349842742,0.0147740316932731,0.0179862099620916,0.0218812709361305,0.0265969935768659,0.0322954646984505,0.0391657227967644,0.0474258731775668,0.0573241758988688,0.0691384203433468,0.0831726964939224,0.0997504891196852,0.119202922022118,0.141851064900488,0.167981614866076,0.197816111441418,0.231475216500982,0.268941421369995,0.310025518872388,0.354343693774205,0.401312339887548,0.450166002687522,0.5,0.549833997312478,0.598687660112452,0.645656306225796,0.689974481127613,0.731058578630005,0.768524783499018,0.802183888558582,0.832018385133925,0.858148935099512,0.880797077977882,0.900249510880315,0.916827303506078,0.930861579656653,0.942675824101131,0.952574126822433,0.960834277203236,0.96770453530155,0.973403006423134,0.978118729063869,0.982013790037908,0.985225968306727,0.987871565015726,0.990048198133096,0.99183742884684,0.993307149075715,0.994513701100549,0.995503726839059,0.996315760100564,0.996981583675292,0.997527376843365,0.99797467961095,0.998341198919826,0.998641480049571,0.99888746396714,0.999088948805599,0.999253971166163,0.999389120640566,0.999499798892921,0.999590432835014,0.999664649869534,0.999725421843899,0.999775183229767,0.999815928095037,0.99984928964194,0.999876605424014,0.999898970806092,0.999917282777148,0.99993227585038,0.999944551475277,0.999954602131298],"text":["y: 4.539787e-05<br />x: -10.0","y: 5.544852e-05<br />x:  -9.8","y: 6.772415e-05<br />x:  -9.6","y: 8.271722e-05<br />x:  -9.4","y: 1.010292e-04<br />x:  -9.2","y: 1.233946e-04<br />x:  -9.0","y: 1.507104e-04<br />x:  -8.8","y: 1.840719e-04<br />x:  -8.6","y: 2.248168e-04<br />x:  -8.4","y: 2.745782e-04<br />x:  -8.2","y: 3.353501e-04<br />x:  -8.0","y: 4.095672e-04<br />x:  -7.8","y: 5.002011e-04<br />x:  -7.6","y: 6.108794e-04<br />x:  -7.4","y: 7.460288e-04<br />x:  -7.2","y: 9.110512e-04<br />x:  -7.0","y: 1.112536e-03<br />x:  -6.8","y: 1.358520e-03<br />x:  -6.6","y: 1.658801e-03<br />x:  -6.4","y: 2.025320e-03<br />x:  -6.2","y: 2.472623e-03<br />x:  -6.0","y: 3.018416e-03<br />x:  -5.8","y: 3.684240e-03<br />x:  -5.6","y: 4.496273e-03<br />x:  -5.4","y: 5.486299e-03<br />x:  -5.2","y: 6.692851e-03<br />x:  -5.0","y: 8.162571e-03<br />x:  -4.8","y: 9.951802e-03<br />x:  -4.6","y: 1.212843e-02<br />x:  -4.4","y: 1.477403e-02<br />x:  -4.2","y: 1.798621e-02<br />x:  -4.0","y: 2.188127e-02<br />x:  -3.8","y: 2.659699e-02<br />x:  -3.6","y: 3.229546e-02<br />x:  -3.4","y: 3.916572e-02<br />x:  -3.2","y: 4.742587e-02<br />x:  -3.0","y: 5.732418e-02<br />x:  -2.8","y: 6.913842e-02<br />x:  -2.6","y: 8.317270e-02<br />x:  -2.4","y: 9.975049e-02<br />x:  -2.2","y: 1.192029e-01<br />x:  -2.0","y: 1.418511e-01<br />x:  -1.8","y: 1.679816e-01<br />x:  -1.6","y: 1.978161e-01<br />x:  -1.4","y: 2.314752e-01<br />x:  -1.2","y: 2.689414e-01<br />x:  -1.0","y: 3.100255e-01<br />x:  -0.8","y: 3.543437e-01<br />x:  -0.6","y: 4.013123e-01<br />x:  -0.4","y: 4.501660e-01<br />x:  -0.2","y: 5.000000e-01<br />x:   0.0","y: 5.498340e-01<br />x:   0.2","y: 5.986877e-01<br />x:   0.4","y: 6.456563e-01<br />x:   0.6","y: 6.899745e-01<br />x:   0.8","y: 7.310586e-01<br />x:   1.0","y: 7.685248e-01<br />x:   1.2","y: 8.021839e-01<br />x:   1.4","y: 8.320184e-01<br />x:   1.6","y: 8.581489e-01<br />x:   1.8","y: 8.807971e-01<br />x:   2.0","y: 9.002495e-01<br />x:   2.2","y: 9.168273e-01<br />x:   2.4","y: 9.308616e-01<br />x:   2.6","y: 9.426758e-01<br />x:   2.8","y: 9.525741e-01<br />x:   3.0","y: 9.608343e-01<br />x:   3.2","y: 9.677045e-01<br />x:   3.4","y: 9.734030e-01<br />x:   3.6","y: 9.781187e-01<br />x:   3.8","y: 9.820138e-01<br />x:   4.0","y: 9.852260e-01<br />x:   4.2","y: 9.878716e-01<br />x:   4.4","y: 9.900482e-01<br />x:   4.6","y: 9.918374e-01<br />x:   4.8","y: 9.933071e-01<br />x:   5.0","y: 9.945137e-01<br />x:   5.2","y: 9.955037e-01<br />x:   5.4","y: 9.963158e-01<br />x:   5.6","y: 9.969816e-01<br />x:   5.8","y: 9.975274e-01<br />x:   6.0","y: 9.979747e-01<br />x:   6.2","y: 9.983412e-01<br />x:   6.4","y: 9.986415e-01<br />x:   6.6","y: 9.988875e-01<br />x:   6.8","y: 9.990889e-01<br />x:   7.0","y: 9.992540e-01<br />x:   7.2","y: 9.993891e-01<br />x:   7.4","y: 9.994998e-01<br />x:   7.6","y: 9.995904e-01<br />x:   7.8","y: 9.996646e-01<br />x:   8.0","y: 9.997254e-01<br />x:   8.2","y: 9.997752e-01<br />x:   8.4","y: 9.998159e-01<br />x:   8.6","y: 9.998493e-01<br />x:   8.8","y: 9.998766e-01<br />x:   9.0","y: 9.998990e-01<br />x:   9.2","y: 9.999173e-01<br />x:   9.4","y: 9.999323e-01<br />x:   9.6","y: 9.999446e-01<br />x:   9.8","y: 9.999546e-01<br />x:  10.0"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(70,130,180,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.958904109589,"r":7.30593607305936,"b":40.9132420091324,"l":48.9497716894977},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-11,11],"tickmode":"array","ticktext":["-10","-5","0","5","10"],"tickvals":[-10,-5,0,5,10],"categoryorder":"array","categoryarray":["-10","-5","0","5","10"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Z","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.0499500623444273,1.04995006234443],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[-6.93889390390723e-018,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"P(Y)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"75844c8592a":{"x":{},"type":"scatter"}},"cur_data":"75844c8592a","visdat":{"75844c8592a":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p> 여기서 주목할 점은 <span class="math inline">\(X\)</span>가 <span class="math inline">\(- \infty\)</span>에서 <span class="math inline">\(\infty\)</span> 까지 변한다 해도 <span class="math inline">\(P(Y=1 | X_{1i})\)</span>의 값은 0에서 1까지 변한다는 점입니다. 앞에서 잠깐 언급한 대로 <span class="math inline">\(P(Y=1 | X_{1i})\)</span>는 확률이고 당연히 그 범위는 0에서 1이어야 합니다.</p>
<p> 위와 같은 <span class="math inline">\(S\)</span> 모양과 비슷한 곡선을 로지스틱 곡선이라고 합니다. 만약 데이터가 <span class="math inline">\(X\)</span>가 작을 때 결과변수가 0인 데이터가 다수 관측되어 지다가 <span class="math inline">\(X\)</span>가 증가하면서 결과변수 값이 1인 데이터가 다수가 되는 상황이라면, 이러한 비율을 가지는 데이터를 이 로지스틱 곡선에 <strong>끼워 맞추는</strong> 것이 로지스틱 회귀분석이라고 할 수 있습니다.</p>
<p> 여기서 다시 처음으로 돌아가 생각해보겠습니다. 어떻게 로지스틱 회귀 방정식은 다음과 같이 만들어진 걸까요?</p>
<p><span class="math display">\[ P(Y=1 | X_{1i}) = \frac{1}{1 + e^{-(b_{0} + b_{1}X_{1i})}}\]</span></p>
<p> 제 경우 이것을 이해하기란 쉽지 않았습니다. 하지만 지금부터 제가 이해한 만큼 설명해보려 합니다.</p>
<p> 먼저 우리가 알고 있는 선형회귀는 선형성이라는 가정을 가지고 있습니다. 즉, 선형회귀의 모형이 타당하려면, 해당 관측자료의 결과변수와 예측변수간에 관계가 선형이어야 합니다. 그런데 결과변수가 0과 1일 경우 이러한 선형성 가정이 더 이상 성립하지 않게 됩니다. 여기서 바로 이런 선형성 가정을 성립시키기 위해 특별히 고안해낸 방법을 도입하게 됩니다. <strong>바로, 확률인 결과변수에 로짓변환을 시켜 선형인 예측변수와 연결하는 방법이 그것입니다.</strong></p>
<p> 먼저 로짓변환부터 알아보겠습니다. 0과 1사이에서 변화하는 확률인 <span class="math inline">\(P(Y=1|X_{1i})\)</span>은 설명변수인 <span class="math inline">\(X_{1i}\)</span>의 함수입니다. 이러한 함수를 <span class="math inline">\(\mu(X_{1i})\)</span>라고 하겠습니다. 이러한 <span class="math inline">\(\mu(X_{1i})\)</span>가 0에서 1까지 변화하면</p>
<p><span class="math display">\[\frac{\mu(X_{1i})}{1-\mu(X_{1i})}\]</span></p>
<p> 위의 식은 다음 그래프 0에서 <span class="math inline">\(\infty\)</span> 까지 변화하게 됩니다.</p>
<pre class="r"><code>myfun_1 &lt;- function(mu_var) {mu_var / (1 - mu_var)};
ggplot(data.frame(x= c(0, 1)), aes(x=x)) + 
  stat_function(fun = myfun_1, geom=&quot;line&quot;, size = 1.2, color = &#39;steelblue&#39;) + 
  xlab(&quot;mu&quot;) +
  ylab(paste(&quot;odds&quot;)) +
  theme_minimal() -&gt; p_2; ggplotly(p_2)</code></pre>
<div id="htmlwidget-2" style="width:576px;height:384px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"data":[{"x":[0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,1],"y":[0,0.0101010101010101,0.0204081632653061,0.0309278350515464,0.0416666666666667,0.0526315789473684,0.0638297872340425,0.0752688172043011,0.0869565217391304,0.0989010989010989,0.111111111111111,0.123595505617978,0.136363636363636,0.149425287356322,0.162790697674419,0.176470588235294,0.19047619047619,0.204819277108434,0.219512195121951,0.234567901234568,0.25,0.265822784810127,0.282051282051282,0.298701298701299,0.315789473684211,0.333333333333333,0.351351351351351,0.36986301369863,0.388888888888889,0.408450704225352,0.428571428571429,0.449275362318841,0.470588235294118,0.492537313432836,0.515151515151515,0.538461538461539,0.5625,0.587301587301587,0.612903225806452,0.639344262295082,0.666666666666667,0.694915254237288,0.724137931034483,0.754385964912281,0.785714285714286,0.818181818181818,0.851851851851852,0.886792452830189,0.923076923076923,0.96078431372549,1,1.04081632653061,1.08333333333333,1.12765957446809,1.17391304347826,1.22222222222222,1.27272727272727,1.32558139534884,1.38095238095238,1.4390243902439,1.5,1.56410256410256,1.63157894736842,1.7027027027027,1.77777777777778,1.85714285714286,1.94117647058824,2.03030303030303,2.125,2.2258064516129,2.33333333333333,2.44827586206897,2.57142857142857,2.7037037037037,2.84615384615385,3,3.16666666666667,3.34782608695652,3.54545454545455,3.76190476190476,4,4.26315789473684,4.55555555555556,4.88235294117647,5.25,5.66666666666667,6.14285714285714,6.69230769230769,7.33333333333333,8.09090909090909,9,10.1111111111111,11.5,13.2857142857143,15.6666666666667,19,24,32.3333333333333,49,98.9999999999999,null],"text":["y:  0.00000000<br />x: 0.00","y:  0.01010101<br />x: 0.01","y:  0.02040816<br />x: 0.02","y:  0.03092784<br />x: 0.03","y:  0.04166667<br />x: 0.04","y:  0.05263158<br />x: 0.05","y:  0.06382979<br />x: 0.06","y:  0.07526882<br />x: 0.07","y:  0.08695652<br />x: 0.08","y:  0.09890110<br />x: 0.09","y:  0.11111111<br />x: 0.10","y:  0.12359551<br />x: 0.11","y:  0.13636364<br />x: 0.12","y:  0.14942529<br />x: 0.13","y:  0.16279070<br />x: 0.14","y:  0.17647059<br />x: 0.15","y:  0.19047619<br />x: 0.16","y:  0.20481928<br />x: 0.17","y:  0.21951220<br />x: 0.18","y:  0.23456790<br />x: 0.19","y:  0.25000000<br />x: 0.20","y:  0.26582278<br />x: 0.21","y:  0.28205128<br />x: 0.22","y:  0.29870130<br />x: 0.23","y:  0.31578947<br />x: 0.24","y:  0.33333333<br />x: 0.25","y:  0.35135135<br />x: 0.26","y:  0.36986301<br />x: 0.27","y:  0.38888889<br />x: 0.28","y:  0.40845070<br />x: 0.29","y:  0.42857143<br />x: 0.30","y:  0.44927536<br />x: 0.31","y:  0.47058824<br />x: 0.32","y:  0.49253731<br />x: 0.33","y:  0.51515152<br />x: 0.34","y:  0.53846154<br />x: 0.35","y:  0.56250000<br />x: 0.36","y:  0.58730159<br />x: 0.37","y:  0.61290323<br />x: 0.38","y:  0.63934426<br />x: 0.39","y:  0.66666667<br />x: 0.40","y:  0.69491525<br />x: 0.41","y:  0.72413793<br />x: 0.42","y:  0.75438596<br />x: 0.43","y:  0.78571429<br />x: 0.44","y:  0.81818182<br />x: 0.45","y:  0.85185185<br />x: 0.46","y:  0.88679245<br />x: 0.47","y:  0.92307692<br />x: 0.48","y:  0.96078431<br />x: 0.49","y:  1.00000000<br />x: 0.50","y:  1.04081633<br />x: 0.51","y:  1.08333333<br />x: 0.52","y:  1.12765957<br />x: 0.53","y:  1.17391304<br />x: 0.54","y:  1.22222222<br />x: 0.55","y:  1.27272727<br />x: 0.56","y:  1.32558140<br />x: 0.57","y:  1.38095238<br />x: 0.58","y:  1.43902439<br />x: 0.59","y:  1.50000000<br />x: 0.60","y:  1.56410256<br />x: 0.61","y:  1.63157895<br />x: 0.62","y:  1.70270270<br />x: 0.63","y:  1.77777778<br />x: 0.64","y:  1.85714286<br />x: 0.65","y:  1.94117647<br />x: 0.66","y:  2.03030303<br />x: 0.67","y:  2.12500000<br />x: 0.68","y:  2.22580645<br />x: 0.69","y:  2.33333333<br />x: 0.70","y:  2.44827586<br />x: 0.71","y:  2.57142857<br />x: 0.72","y:  2.70370370<br />x: 0.73","y:  2.84615385<br />x: 0.74","y:  3.00000000<br />x: 0.75","y:  3.16666667<br />x: 0.76","y:  3.34782609<br />x: 0.77","y:  3.54545455<br />x: 0.78","y:  3.76190476<br />x: 0.79","y:  4.00000000<br />x: 0.80","y:  4.26315789<br />x: 0.81","y:  4.55555556<br />x: 0.82","y:  4.88235294<br />x: 0.83","y:  5.25000000<br />x: 0.84","y:  5.66666667<br />x: 0.85","y:  6.14285714<br />x: 0.86","y:  6.69230769<br />x: 0.87","y:  7.33333333<br />x: 0.88","y:  8.09090909<br />x: 0.89","y:  9.00000000<br />x: 0.90","y: 10.11111111<br />x: 0.91","y: 11.50000000<br />x: 0.92","y: 13.28571429<br />x: 0.93","y: 15.66666667<br />x: 0.94","y: 19.00000000<br />x: 0.95","y: 24.00000000<br />x: 0.96","y: 32.33333333<br />x: 0.97","y: 49.00000000<br />x: 0.98","y: 99.00000000<br />x: 0.99","y:         Inf<br />x: 1.00"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(70,130,180,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.958904109589,"r":7.30593607305936,"b":40.9132420091324,"l":43.1050228310502},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"mu","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-4.95,103.95],"tickmode":"array","ticktext":["0","25","50","75","100"],"tickvals":[0,25,50,75,100],"categoryorder":"array","categoryarray":["0","25","50","75","100"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"odds","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"75845c542ce6":{"x":{},"type":"scatter"}},"cur_data":"75845c542ce6","visdat":{"75845c542ce6":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p> 참고로 이 식에 대해 좀 더 생각해보겠습니다. 이 식의 분자 <span class="math inline">\(\mu(X_{1i})\)</span>는 관측값이 <span class="math inline">\(X_{1i}\)</span>일 때 예측값이 1이 될 확률 <span class="math inline">\(P(Y = 1 | X_{1i})\)</span>입니다. 반대로 분모 <span class="math inline">\(1-\mu(X_{1i})\)</span>는 해당 확률을 1에서 뺀 값이므로 관측값이 <span class="math inline">\(X_{1i}\)</span>일 때 예측값이 0이 될 확률이라고 할 수 있습니다. 즉 개념적으로 이 식을 설명하면 다음과 같이 표현할 수 있습니다.</p>
<p><span class="math display">\[\frac{P(Y = 1 | X_{1i})}{P(Y = 0 | X_{1i})}\]</span></p>
<p>  <span class="math inline">\(P(Y = 1 | X_{1i})\)</span>은 예측값이 1이 되는 확률로 일종의 사건이 발생할 확률로 생각할 수 있고, 반대로 <span class="math inline">\(P(Y = 0 | X_{1i})\)</span>은 예측값이 0이 되는 확률로 사건이 발생하지 않을 확률로 생각할 수 있습니다. 이러한 수식을 <strong>오즈(odds)</strong>라고 합니다.</p>
<p> 바로 이 0부터 <span class="math inline">\(\infty\)</span> 까지 변화하는 오즈(odds)에 로그를 씌우면 전체의 값이 <span class="math inline">\(-\infty\)</span>에서 <span class="math inline">\(-\infty\)</span>까지 변화하게 됩니다. 즉 다음의 식은 변화범위가 <span class="math inline">\(-\infty\)</span>에서 <span class="math inline">\(-\infty\)</span>까지가 됩니다.</p>
<p><span class="math display">\[log \left(\frac{\mu(X_{1i})}{1-\mu(X_{1i})} \right)\]</span></p>
<pre class="r"><code>myfun_2 &lt;- function(mu_var) {log(mu_var / (1 - mu_var))};
ggplot(data.frame(x= c(0, 1)), aes(x=x)) + 
  stat_function(fun = myfun_2, geom=&quot;line&quot;, size = 1.2, color = &#39;steelblue&#39;) + 
  labs(x = &quot;mu&quot;, y = &quot;Y&quot;) +
  theme_minimal() -&gt; p_3; ggplotly(p_3)</code></pre>
<div id="htmlwidget-3" style="width:576px;height:384px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"data":[{"x":[0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39,0.4,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.7,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,1],"y":[null,-4.59511985013459,-3.89182029811063,-3.47609868983527,-3.17805383034795,-2.94443897916644,-2.75153531304195,-2.58668934409794,-2.4423470353692,-2.31363492918063,-2.19722457733622,-2.09074109693377,-1.99243016469021,-1.90095876119305,-1.81528996663825,-1.73460105538811,-1.65822807660353,-1.58562726374038,-1.51634748936809,-1.450010175506,-1.38629436111989,-1.3249254147436,-1.26566637333128,-1.20831120592453,-1.15267950993839,-1.09861228866811,-1.04596855518269,-0.994622575144062,-0.944461608840851,-0.895384047054841,-0.847297860387204,-0.800119300112113,-0.75377180237638,-0.708185057924486,-0.663294217410264,-0.619039208406223,-0.575364144903562,-0.532216813747308,-0.489548225318706,-0.447312218043665,-0.405465108108164,-0.363965377201412,-0.322773392263051,-0.281851152140988,-0.241162056816888,-0.200670695462151,-0.160342650075179,-0.120144311842063,-0.0800427076735365,-0.0400053346136992,0,0.0400053346136992,0.0800427076735366,0.120144311842063,0.160342650075179,0.200670695462151,0.241162056816888,0.281851152140988,0.322773392263051,0.363965377201411,0.405465108108164,0.447312218043665,0.489548225318706,0.532216813747308,0.575364144903562,0.619039208406224,0.663294217410264,0.708185057924486,0.75377180237638,0.800119300112113,0.847297860387204,0.895384047054841,0.944461608840851,0.994622575144062,1.04596855518269,1.09861228866811,1.15267950993839,1.20831120592453,1.26566637333128,1.3249254147436,1.38629436111989,1.450010175506,1.51634748936809,1.58562726374038,1.65822807660353,1.73460105538811,1.81528996663825,1.90095876119305,1.99243016469021,2.09074109693377,2.19722457733622,2.31363492918063,2.44234703536921,2.58668934409794,2.75153531304195,2.94443897916644,3.17805383034794,3.47609868983527,3.89182029811063,4.59511985013459,null],"text":["y:        -Inf<br />x: 0.00","y: -4.59511985<br />x: 0.01","y: -3.89182030<br />x: 0.02","y: -3.47609869<br />x: 0.03","y: -3.17805383<br />x: 0.04","y: -2.94443898<br />x: 0.05","y: -2.75153531<br />x: 0.06","y: -2.58668934<br />x: 0.07","y: -2.44234704<br />x: 0.08","y: -2.31363493<br />x: 0.09","y: -2.19722458<br />x: 0.10","y: -2.09074110<br />x: 0.11","y: -1.99243016<br />x: 0.12","y: -1.90095876<br />x: 0.13","y: -1.81528997<br />x: 0.14","y: -1.73460106<br />x: 0.15","y: -1.65822808<br />x: 0.16","y: -1.58562726<br />x: 0.17","y: -1.51634749<br />x: 0.18","y: -1.45001018<br />x: 0.19","y: -1.38629436<br />x: 0.20","y: -1.32492541<br />x: 0.21","y: -1.26566637<br />x: 0.22","y: -1.20831121<br />x: 0.23","y: -1.15267951<br />x: 0.24","y: -1.09861229<br />x: 0.25","y: -1.04596856<br />x: 0.26","y: -0.99462258<br />x: 0.27","y: -0.94446161<br />x: 0.28","y: -0.89538405<br />x: 0.29","y: -0.84729786<br />x: 0.30","y: -0.80011930<br />x: 0.31","y: -0.75377180<br />x: 0.32","y: -0.70818506<br />x: 0.33","y: -0.66329422<br />x: 0.34","y: -0.61903921<br />x: 0.35","y: -0.57536414<br />x: 0.36","y: -0.53221681<br />x: 0.37","y: -0.48954823<br />x: 0.38","y: -0.44731222<br />x: 0.39","y: -0.40546511<br />x: 0.40","y: -0.36396538<br />x: 0.41","y: -0.32277339<br />x: 0.42","y: -0.28185115<br />x: 0.43","y: -0.24116206<br />x: 0.44","y: -0.20067070<br />x: 0.45","y: -0.16034265<br />x: 0.46","y: -0.12014431<br />x: 0.47","y: -0.08004271<br />x: 0.48","y: -0.04000533<br />x: 0.49","y:  0.00000000<br />x: 0.50","y:  0.04000533<br />x: 0.51","y:  0.08004271<br />x: 0.52","y:  0.12014431<br />x: 0.53","y:  0.16034265<br />x: 0.54","y:  0.20067070<br />x: 0.55","y:  0.24116206<br />x: 0.56","y:  0.28185115<br />x: 0.57","y:  0.32277339<br />x: 0.58","y:  0.36396538<br />x: 0.59","y:  0.40546511<br />x: 0.60","y:  0.44731222<br />x: 0.61","y:  0.48954823<br />x: 0.62","y:  0.53221681<br />x: 0.63","y:  0.57536414<br />x: 0.64","y:  0.61903921<br />x: 0.65","y:  0.66329422<br />x: 0.66","y:  0.70818506<br />x: 0.67","y:  0.75377180<br />x: 0.68","y:  0.80011930<br />x: 0.69","y:  0.84729786<br />x: 0.70","y:  0.89538405<br />x: 0.71","y:  0.94446161<br />x: 0.72","y:  0.99462258<br />x: 0.73","y:  1.04596856<br />x: 0.74","y:  1.09861229<br />x: 0.75","y:  1.15267951<br />x: 0.76","y:  1.20831121<br />x: 0.77","y:  1.26566637<br />x: 0.78","y:  1.32492541<br />x: 0.79","y:  1.38629436<br />x: 0.80","y:  1.45001018<br />x: 0.81","y:  1.51634749<br />x: 0.82","y:  1.58562726<br />x: 0.83","y:  1.65822808<br />x: 0.84","y:  1.73460106<br />x: 0.85","y:  1.81528997<br />x: 0.86","y:  1.90095876<br />x: 0.87","y:  1.99243016<br />x: 0.88","y:  2.09074110<br />x: 0.89","y:  2.19722458<br />x: 0.90","y:  2.31363493<br />x: 0.91","y:  2.44234704<br />x: 0.92","y:  2.58668934<br />x: 0.93","y:  2.75153531<br />x: 0.94","y:  2.94443898<br />x: 0.95","y:  3.17805383<br />x: 0.96","y:  3.47609869<br />x: 0.97","y:  3.89182030<br />x: 0.98","y:  4.59511985<br />x: 0.99","y:         Inf<br />x: 1.00"],"type":"scatter","mode":"lines","line":{"width":4.53543307086614,"color":"rgba(70,130,180,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.958904109589,"r":7.30593607305936,"b":40.9132420091324,"l":48.9497716894977},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.00","0.25","0.50","0.75","1.00"],"tickvals":[0,0.25,0.5,0.75,1],"categoryorder":"array","categoryarray":["0.00","0.25","0.50","0.75","1.00"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"mu","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-5.05463183514805,5.05463183514805],"tickmode":"array","ticktext":["-5.0","-2.5","0.0","2.5","5.0"],"tickvals":[-5,-2.5,0,2.5,5],"categoryorder":"array","categoryarray":["-5.0","-2.5","0.0","2.5","5.0"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"Y","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"75845f6cfcf":{"x":{},"type":"scatter"}},"cur_data":"75845f6cfcf","visdat":{"75845f6cfcf":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>바로 이러한 변환을 로짓변환이라고 합니다.</p>
<p> 확률값인 <span class="math inline">\(\mu(X_{1i})\)</span>를 로짓변환을 통해 <span class="math inline">\(-\infty\)</span>에서 <span class="math inline">\(-\infty\)</span>까지 변화되는 값으로 변환시키고 이렇게 변환된 값을 마찬가지로 <span class="math inline">\(-\infty\)</span>에서 <span class="math inline">\(-\infty\)</span>까지 변화할 수 있는 선형예측 함수인 <span class="math inline">\(\beta_{1} X_{1i}\)</span>와 연결하여 선형성 가정 위반을 회피합니다. 이를 수식으로 표현하면 다음과 같게 됩니다.</p>
<p><span class="math display">\[log \left(\frac{\mu(X_{1i})}{1-\mu(X_{1i})} \right) = b_{0} + b_{1}X_{1i}\]</span></p>
<p> 위의 수식을 고등학교 수학 실력을 총동원해 <span class="math inline">\(\mu(X_{1i})\)</span>에 관한 식으로 정리하면 다음과 같게 됩니다.</p>
<p><span class="math display">\[\mu(X_{1i}) = \frac{e^{(b_{0} + b_{1}X_{1i})}}{1+e^{(b_{0} + b_{1}X_{1i})}}\]</span></p>
<p> 여기서 한 번 더 고등학교 수학실력을 발휘하면</p>
<p><span class="math display">\[P(Y=1|X_{1i}) = \mu(X_{1i}) = \frac{1}{1+e^{-(b_{0} + b_{1}X_{1i})}}\]</span></p>
<p> 즉 처음에 등장한 로지스틱 회귀방정식이 나오게 되는 것입니다.</p>
<p> 예측변수가 여러 개(<span class="math inline">\(X_{1i}, X_{2i}, ..., X_{ni}\)</span>)인 로지스틱 회귀 방정식은 단순히 변수들을 위와 동일한 식에 추가하여 주기만 하면 되고 결국 다음과 같게 됩니다.</p>
<p><span class="math display">\[P(Y) = \frac{1}{1 + e^{-(b_{0} + b_{1}X_{1i} + b_{2}X_{2i} + ... + b_{n}X_{ni})}}\]</span></p>
<ul>
<li>(요약정리) 선형회귀의 모형이 타당하려면, 해당 관측 자료에 선형 관계가 존재해야 한다. 그런데 결과변수가 범주형이면 그러한 가정이 깨진다. 로짓변환은 비선형 관계를 선형 관계로 표현하는 한 방법이다. 로지스틱 회귀 방정식은 바로 그러한 원리에 기초한다. 즉, 다중 선형 관계를 로그 항(logit)들로 표현함으로써 선형성 가정 위반 문제를 극복한다.</li>
</ul>
<div id="모형의-평가-로그-가능도-통계량" class="section level3">
<h3>모형의 평가: 로그 가능도 통계량</h3>
<p> 로지스틱 회귀에서도 선형회귀에서와 마찬가지로 관측값과 예측값을 비교해서 모형의 적합도를 평가합니다. 이때 쓰이는 척도가 로그우도(log-likelihood)입니다. 로지스틱 회귀 모델에서 로그우도를 계산하는 식은 다음과 같습니다.</p>
<p><span class="math display">\[LL = \sum_{i=1}^{N} \left[  Y_{i} \ln(P(Y_{i})) + (1-Y_{i})\ln(1 - P(Y_{i}))  \right]\]</span></p>
<p> 머신러닝 학습을 하게 되면 <strong>우도</strong>라는 말이 자주 등장합니다. 그리고 그와 함께 따라 다니는 개념이 <strong>최대우도추정(Maximum Likelihood Estimation)</strong>입니다. 우도와 최대우도추정을 이번 포스트에서 모두 다루기는 어렵습니다. 언젠가 자세한 설명을 한 포스트를 올리겠습니다.</p>
<p> 다만, 이번 포스트에서는 왜 로그가능도를 계산하는 식이 위와같이 나왔는가에 대한 설명을 수학적으로만 하려고 합니다. 매우 어려운 개념을 포함하므로 이해하기 어려우시면 다음 올리는 포스트를 참고하여 주시기 바랍니다.</p>
<p> 로지스틱 회귀의 결과변수는 0 또는 1의 값을 가지는 베르누이 확률변수입니다.(이해가…죄송합니다.) 이 말을 <span class="math inline">\(Y \text{~} Brenoulli(P)\)</span>라고도 표현합니다. 만약 1이 나올 확률이 <span class="math inline">\(P\)</span>라고 한다면 반대로 0이 나올 확률은 <span class="math inline">\(1-P\)</span>입니다.</p>
<p><span class="math display">\[ \text{Bernoulli}(Y;P) = \begin{cases} P &amp; \text{if } Y_{i} = 1 \\ 1 - P &amp; \text{if } Y_{i}=0 \end{cases} \]</span></p>
<p> 만약 위의 표현식을 조건문 없이 표현한다고 하면 어떻게 될까요?</p>
<p><span class="math display">\[ \text{Bernoulli}(Y;P) =  P^{Y_{i}}(1-P)^{1-Y_{i}} \quad \quad (Y_{i} = 0, 1)\]</span></p>
<p> <span class="math inline">\(Y_{i}\)</span>에 직접 0과 1을 대입하여 생각해보면 위의 식과 아래의 식이 동일함을 알 수 있습니다. 로지스틱 회귀의 결과변수는 <span class="math inline">\(P^{Y_{i}}(1-P)^{1-Y_{i}}\)</span>인 확률분포를 따릅니다. 1부터</p>
<ul>
<li>로그가능도는 예측값들과 실제 관측값들에 관한 확률들의 합이다.</li>
<li>로그가능도 통계량은 모형이 적합된 후에도 여전히 설명되지 않는 정보의 양을 나타낸다.</li>
<li>이는 마치 다중회귀의 잔차제곱합(<span class="math inline">\(SS_{R}\)</span>)과 비슷하다.</li>
<li>로그가능도 통계량이 크다는 것은 설명되지 않은 관측이 많이 남아 있다는 것이다.</li>
<li>로그가능도 통계량이 큰 통계적 모형은 자료에 별로 적합하지 않다고 할 수 있다.</li>
</ul>
</div>
<div id="모형의-평가-이탈도-통계량" class="section level3">
<h3>모형의 평가: 이탈도 통계량</h3>
<ul>
<li>deviance: <span class="math inline">\(-2LL\)</span></li>
</ul>
<p><span class="math display">\[Logistic \ Regression \ Deviance = -2 \times LL\]</span></p>
<ul>
<li><p>로그가능도를 그대로 사용하는 것보다는 이 이탈도를 사용하는 것이 (거의) 항상 더 편한데, 왜냐하면 이탈도는 카이제곱 분포를 따르기 때문이다.</p></li>
<li><p>다중회귀에서는 흔히 모든 점수의 평균을 기저 모형으로 사용한다. 다른 어떤 정보도 없는 상태에서 결과를 예측하기 위해 사용할 수 있는 최선의 모형이 평균이기 때문이다.</p></li>
<li><p>다중회귀에서는 평균이 기저 모형이었지만 로지스틱 회귀에서는 가장 자주 발생한 결과가 기저 모형이다. 기저 로지스틱 모형은 상수 하나만 포함한 모형에 해당한다.</p></li>
<li><p>기저모형에 더 많은 예측변수를 추가함으로써 모형을 좀 더 개선할 수 있다.</p></li>
</ul>
<p><span class="math display">\[  \chi^{2} = (-2LL(기저모형)) - (-2LL(새모형)) \]</span></p>
<p><span class="math display">\[  \chi^{2} = 2LL(새모형) - 2LL(기저모형) \]</span></p>
<p><span class="math display">\[ df = k_{new \ model}  - k_{base \ model}\]</span></p>
<ul>
<li><p>카이제곱은 새 모형의 이탈도에서 기저 모형의 이탈도를 뺀 값이다. 이 차이를 가능도비(likelihood ratio)라고 한다.</p></li>
<li><p>df는 자유도인데 새 모형의 매개 변수에서 기저 모형의 매개변수 개수를 뺀 것이다.</p></li>
<li><p>가능도비는 자유도가 <span class="math inline">\(df\)</span>인 카이제곱 분포를 따른다.</p></li>
<li><p>기저모형의 매개변수는 항상 하나이다. 따라서, 이후의 새 모형들의 자유도는 항상 예측변수 개수에 1을 더한 값이다.</p></li>
</ul>
</div>
<div id="모형의-평가-r과-r2" class="section level3">
<h3>모형의 평가: <span class="math inline">\(R\)</span>과 <span class="math inline">\(R^{2}\)</span></h3>
<ul>
<li><p>로지스틱 회귀에도 다중회귀의 <span class="math inline">\(R\)</span>과 좀 더 직접적으로 대응되는 통계량이 있다. 바로 R 통계량(R-statistic)이다.</p></li>
<li><p>이 R 통계량은 결과변수와 각 예측변수 사이의 편상관계수로, 그 값은 -1에서 1까지이다.</p></li>
<li><p>R 통계량의 값이 양수이면 예측변수의 값이 증가함에 따라 결과의 발생 가능도도 증가한다는 뜻이고, 값이 음수이면 예측변수의 값이 증가함에 따라 결과의 발생 가능도도 증가한다는 뜻이다.</p></li>
<li><p>R 통계량의 크기가 작다는 것은그 변수가 모형에 조금만 기여한다는 뜻이다.</p></li>
</ul>
<p><span class="math display">\[R = \sqrt \frac{z^{2} - 2df}{-2LL}\]</span></p>
<ul>
<li><span class="math inline">\(z^{2}\)</span>은 왈드 통계량(Wald Statistic)이다.</li>
<li>R 값은 왈드 통계량에 의존하므로, 정확한 측도는 절대 아니다. 그리고 이 값의 제곱을 선형회귀에서처럼 해석하는 것은 유효하지 않다.</li>
<li>로지스틱 회귀에서 선형회귀의 <span class="math inline">\(R^{2}\)</span>에 해당하는 좋은 측도 중 하나는 <strong>호스머-렘쇼 측도</strong>가 있다.</li>
</ul>
<p><span class="math display">\[R^{2}_{L} = \frac{-2LL(모형)}{-2LL(기저모형)}\]</span></p>
<p><span class="math display">\[R^{2}_{L} = \frac{-2LL(기저모형) - 2LL(새모형)}{-2LL(기저모형)}\]</span></p>
<ul>
<li>콕스-스넬 <span class="math inline">\(R^{2}_{CS}\)</span></li>
</ul>
<p><span class="math display">\[R^{2}_{CS} = 1 - exp \left( \frac{(-2LL(새모형) - (-2LL(기저모형))}{n} \right)\]</span></p>
<ul>
<li>네이글커크의 <span class="math inline">\(R^{2}_{N}\)</span></li>
</ul>
<p><span class="math display">\[R^{2}_{N} = \frac{R^{2}_{CS}}{1 - exp \left( -\frac{-2LL(기저모형)}{n} \right)}\]</span></p>
</div>
<div id="모형의-평가-정보기준" class="section level3">
<h3>모형의 평가: 정보기준</h3>
<ul>
<li>아카이케 정보기준(AIC)</li>
</ul>
<p><span class="math display">\[AIC = -2LL + 2k\]</span></p>
<ul>
<li>베이즈 정보기준(BIC)</li>
</ul>
<p><span class="math display">\[BIC = -2LL + 2k \times log(n)\]</span></p>
</div>
<div id="예측변수의-기여도-평가-z-통계량" class="section level3">
<h3>예측변수의 기여도 평가: z 통계량</h3>
<ul>
<li>로지스틱 회귀에서도 개별 예측변수의 기여도도 측정할 필요가 있다. 선형회귀에서는 추정된 회귀계수(b)와 그 표준오차를 이용해서 <span class="math inline">\(t\)</span> 통계량을 계산했다. 로지스틱 회귀에서도 그에 대응되는 통계량이 있는데, 바로 z 통계량이다.(z-statistic)</li>
</ul>
<p><span class="math display">\[z = \frac{b}{SE_{b}}\]</span></p>
<ul>
<li>z 통계량은 그냥 회귀계수를 자신의 표준오차로 나눈 것이다.</li>
<li>z 통계량을 사용할 때는 조금 조심해야 하는데, 왜냐하면 회귀계수가 클 때는 표준오차가 상승(inflation)해서 z 통계량이 과소평가될 수 있기 때문이다.</li>
</ul>
</div>
<div id="승산비" class="section level3">
<h3>승산비</h3>
<ul>
<li>odds: 승산, 그 사건이 발생할 확률을 그 사건이 발생하지 않을 확률로 나눈 것</li>
<li>odds ratio: 승산비, 변경 후의 승산을 변경 전의 승산으로 나눈 것</li>
</ul>
<p><span class="math display">\[odds = \frac{P(사건)}{P(사건없음)}\]</span></p>
<p><span class="math display">\[P(사건 Y) = \frac{1}{1 + e^{-(b_{0} + b_{1}X_{1i})}}\]</span></p>
<p><span class="math display">\[P(사건없음) = 1 - P(사건 Y)\]</span></p>
<ul>
<li>예측변수를 1단위 변경하기 전과 후의 승산들을 구하고 둘의 변화 비율을 계산하면 승산비를 구할 수 있다.</li>
</ul>
<p><span class="math display">\[\Delta 승산 = \frac{예측변수의 \ 1단위 \ 변경 \ 이후의 \ 승산}{원래의 \ 승산}\]</span></p>
</div>
<div id="여러-로지스틱-회귀-방법" class="section level3">
<h3>여러 로지스틱 회귀 방법</h3>
<div id="강제도입법" class="section level4">
<h4>강제도입법</h4>
</div>
<div id="단계적-방법" class="section level4">
<h4>단계적 방법</h4>
<ul>
<li>전진, 후진, 전후진 및 후전진 방법 등이 있다.</li>
</ul>
</div>
<div id="방법의-선택" class="section level4">
<h4>방법의 선택</h4>
<ul>
<li>후진 방향의 변수 제거에 비해 전진 방향의 변수 선택은 억제인자 효과와 관련된 예측변수를 배제할 가능성이 크다. 따라서 전진 방향의 단계적 방법에서는 제2종오류(즉, 실제로 결과변수를 예측하는 예측변수를 빼먹는 오류)를 범할 위험이 크다.</li>
</ul>
</div>
</div>
</div>
<div id="가정과-잠재적-문제점" class="section level2">
<h2>가정과 잠재적 문제점</h2>
<div id="가정" class="section level3">
<h3>가정</h3>
<ul>
<li><ol style="list-style-type: decimal">
<li>선형성: 임의의 연속 예측변수들과 결과변수의 로짓 관계가 선형이어야 한다.</li>
</ol></li>
</ul>
<p><span class="math display">\[\log(\frac{\mu}{1 - \mu}) = \eta(x)  = x\beta\]</span></p>
<ul>
<li><ol start="2" style="list-style-type: decimal">
<li>오차의 독립성: 사례들 사이에 관계가 없어야 한다.</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>다중공선성 부재: VIF 통계량, 비례 비중심화 외적 행렬(scaled, uncentered cross-products matrix)의 고유값들, 분산비율의 조건 지수들로 확인</li>
</ol></li>
</ul>
</div>
<div id="faiilure-to-converge에-관한-r-메세지" class="section level3">
<h3>faiilure to converge에 관한 R 메세지</h3>
<ul>
<li>반복과정을 통해 통계적 절차를 수행할 때 최대 반복 횟수가 되었어도 값이 수렴되지 않았다는 뜻이다. 이런 메세지가 나왔다면 R이 출력한 모든 결과를 무시해야 한다.</li>
</ul>
</div>
<div id="예측변수로부터의-불완전-정보" class="section level3">
<h3>예측변수로부터의 불완전 정보</h3>
<table>
<thead>
<tr class="header">
<th align="center">담배를 피우는가?</th>
<th align="center">토마토를 먹는가?</th>
<th align="center">암에 걸렸는가?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">예</td>
<td align="center">아니오</td>
<td align="center">예</td>
</tr>
<tr class="even">
<td align="center">예</td>
<td align="center">예</td>
<td align="center">예</td>
</tr>
<tr class="odd">
<td align="center">아니요</td>
<td align="center">아니요</td>
<td align="center">예</td>
</tr>
<tr class="even">
<td align="center">아니요</td>
<td align="center">예</td>
<td align="center">?????</td>
</tr>
</tbody>
</table>
<ul>
<li>이러한 문제는 교차표를 이용해서 점검해 보아야 한다. 표의 각 칸에 있는 기대 도수들도 살펴볼 필요가 있다. 그 도수들이 모두 1보다 큰지, 그리고 5 미만인 도수가 20%는 넘는지 확인해야 한다.(로지스틱 회귀의 적합성 검정이 그러한 가정을 깔고 있기 때문이다.)</li>
</ul>
</div>
<div id="완전-분리" class="section level3">
<h3>완전 분리</h3>
<ul>
<li><p>로지스틱 회귀가 실패로 끝나는 또 다른 상황은 한 변수 또는 변수들의 한 조합이 결과변수를 완벽하게 예측할 때이다.</p></li>
<li><p>세로축이 0인 삼각형과 1인 삼각형들이 있는데 삼각형들의 범위가 겹치지 않는다. 도둑만큼 무서운 고양이가 없는 것이다. 이러한 상황을 완전분리(complete separation)이라고 한다.</p></li>
<li><p>표본에 15kb과 40kg 사이의 자료가 없으므로, 그 범위의 체중에 대한 확률을 구할 수 없다. R은 이 중간지점에 대한 기울기를 최선을 다해 추측하려 하는데, 그 과정에서 근사값들이 무한대를 향해 발산하는 불안정한 상황이 발생할 수 있다.(즉, 표준오차가 그렇게 크게 나타는 것이다.)</p></li>
</ul>
</div>
</div>
<div id="이번-장에서-사용하는-패키지들" class="section level2">
<h2>이번 장에서 사용하는 패키지들</h2>
<ul>
<li>car, mlogit</li>
</ul>
</div>
<div id="이항-로지스틱-회귀-미끈미끈한-예제-하나" class="section level2">
<h2>이항 로지스틱 회귀: 미끈미끈한 예제 하나</h2>
<ul>
<li>항문, 뱀장어</li>
</ul>
<div id="자료준비" class="section level3">
<h3>자료준비</h3>
<pre class="r"><code>eelData &lt;- read.delim(&#39;eel.dat&#39;, header = T)</code></pre>
<pre class="r"><code>head(eelData)</code></pre>
<pre><code>##       Cured Intervention Duration
## 1 Not Cured No Treatment        7
## 2 Not Cured No Treatment        7
## 3 Not Cured No Treatment        6
## 4     Cured No Treatment        8
## 5     Cured Intervention        7
## 6     Cured No Treatment        6</code></pre>
<pre class="r"><code>eelData$Cured &lt;-relevel(eelData$Cured, &#39;Not Cured&#39;)
eelData$Intervention &lt;- relevel(eelData$Intervention, &#39;No Treatment&#39;)</code></pre>
<pre class="r"><code>eelData %&gt;% str()</code></pre>
<pre><code>## &#39;data.frame&#39;:    113 obs. of  3 variables:
##  $ Cured       : Factor w/ 2 levels &quot;Not Cured&quot;,&quot;Cured&quot;: 1 1 1 2 2 2 1 2 2 1 ...
##  $ Intervention: Factor w/ 2 levels &quot;No Treatment&quot;,..: 1 1 1 1 2 1 2 2 1 1 ...
##  $ Duration    : int  7 7 6 8 7 6 7 7 8 7 ...</code></pre>
</div>
<div id="r을-이용한-기본적인-로지스틱-회귀분석" class="section level3">
<h3>R을 이용한 기본적인 로지스틱 회귀분석</h3>
<ul>
<li>glm()</li>
<li>family 인수에는 분포의 종류(가우스, 이항, 푸아송, 감마 등)를 나타내는 객체를 지정</li>
<li>na.action</li>
<li>Binomial(link = ‘logit’)과 Binomial(link = ‘probit’)</li>
</ul>
<pre class="r"><code>eelmodel_1 &lt;- glm(Cured ~ Intervention, data = eelData, family = binomial())</code></pre>
<pre class="r"><code>eelmodel_2 &lt;- glm(Cured ~ Intervention + Duration, data = eelData, family = binomial())</code></pre>
<pre class="r"><code>eelmodel_1 %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## glm(formula = Cured ~ Intervention, family = binomial(), data = eelData)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5940  -1.0579   0.8118   0.8118   1.3018  
## 
## Coefficients:
##                          Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)               -0.2877     0.2700  -1.065  0.28671   
## InterventionIntervention   1.2287     0.3998   3.074  0.00212 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 154.08  on 112  degrees of freedom
## Residual deviance: 144.16  on 111  degrees of freedom
## AIC: 148.16
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ul>
<li>Null deviance: 154.08 on 112 degrees of freedom</li>
<li>Residual deviance: 144.16 on 111 degrees of freedom</li>
<li>이 이탈도가 클수록 통계적 모형으로서의 이 회귀모형은 자료에 잘 적합하지 않는 것이다.</li>
<li>귀무 이탈도(Null deviance)는 상수만 있고 예측변수는 전혀 없는 모형의 이탈도이다. 즉, -2LL(기저모형)이 바로 귀무 이탈도이다.</li>
<li>잔차 이탈도는 모형의 이탈도, 즉 -2LL이다.</li>
<li>기저 모형의 이탈도는 154.08이지만 거기에 Intervention을 추가하니 이탈로가 144.16으로 감소했다. 이후의 모델이 결과를 좀 더 잘 예측한다.</li>
<li>귀무 이탈도에서 이탈도를 뺀 것이 바로 모형의 개선 정도를 뜻하는 카이제곱 통계량이다.</li>
</ul>
<pre class="r"><code>modelChi &lt;- eelmodel_1$null.deviance - eelmodel_2$deviance
modelChi</code></pre>
<pre><code>## [1] 9.928185</code></pre>
<ul>
<li>귀무 모형의 자유도에서 eelmodel_1 모형의 자유도를 빼면 앞에서 구한 카이제곱 통계량의 자유도가 된다.</li>
</ul>
<pre class="r"><code>chidf &lt;- eelmodel_1$df.null - eelmodel_1$df.residual
chidf</code></pre>
<pre><code>## [1] 1</code></pre>
<ul>
<li>pchisq()
-우리가 원하는 확률은 1에서 <span class="math inline">\(pchisq()\)</span> 함수의 결과를 뺀 것이다.</li>
</ul>
<pre class="r"><code>chisq.prob &lt;- 1 - pchisq(modelChi, chidf)
chisq.prob</code></pre>
<pre><code>## [1] 0.00162767</code></pre>
<ul>
<li><p>따라서, 모형에 Intervention을 포함함으로써 모형의 적합도가 <span class="math inline">\(\chi^{2} = 9.93, p = .002\)</span>로 유의하게 개선되었다는 결론을 내릴 수 있다.</p></li>
<li><p>Intervention 1.22879(Estimate) 0.3998(Error) 3.074(z value) 0.00212(Pr)</p></li>
<li><p><span class="math inline">\(b\)</span>값은 예측변수의 1단위 변화에 따른 결과의 로짓의 변화량을 나타낸다. 결과의 로짓이란 그냥 해당 Y값이 나올 승산의 자연로그이다.</p></li>
<li><p><span class="math inline">\(b=1.23, z=3.07,p&lt;.002\)</span> z 통계량의 유의확률이 .05미만이므로 Intervention은 치료 여부의 유의한 예측변수라고 할 수 있다.</p></li>
<li><p>로지스틱 회귀의 R</p></li>
</ul>
<p><span class="math display">\[R = \sqrt \frac{3.074^2 - 2 \times1}{154.08} = .22\]</span></p>
<ul>
<li><span class="math inline">\(R^{2}_{L}\)</span>: 호스머-램쇼</li>
</ul>
<pre class="r"><code>R2.hl &lt;- modelChi / eelmodel_1$null.deviance
R2.hl</code></pre>
<pre><code>## [1] 0.06443358</code></pre>
<ul>
<li>콕스-스넬 <span class="math inline">\(R^{2}_{CS}\)</span></li>
</ul>
<pre class="r"><code>R.cs &lt;- 1 - exp((eelmodel_1$deviance - eelmodel_1$null.deviance) / 113)
R.cs</code></pre>
<pre><code>## [1] 0.08409487</code></pre>
<ul>
<li>네이글커크의 <span class="math inline">\(R^{2}_{N}\)</span></li>
</ul>
<pre class="r"><code>R.n &lt;- R.cs/(1 - exp( - (eelmodel_1$null.deviance / 113)))
R.n</code></pre>
<pre><code>## [1] 0.112992</code></pre>
<pre class="r"><code>logisticPseudoR2s &lt;- function(LogModel) {
  dev &lt;- LogModel$deviance
  nullDev &lt;- LogModel$null.deviance
  modelN &lt;- length(LogModel$fitted.values)
  R.l &lt;- 1 - dev / nullDev
  R.cs &lt;- 1 - exp( -(nullDev - dev) / modelN)
  R.n &lt;- R.cs / (1 - (exp( - (nullDev / modelN))))
  
  cat(&#39;Pseudo R^2 for logistic regression\n&#39;)
  cat(&#39;Hosmer and Lemeshow R^2 &#39;, round(R.l, 3), &#39;\n&#39;)
  cat(&#39;Cox and Shell R^2&#39;, round(R.cs, 3), &#39;\n&#39;)
  cat(&#39;Nagekkerke R^2&#39;, round(R.n, 3), &#39;\n&#39;)
}

logisticPseudoR2s(eelmodel_1)</code></pre>
<pre><code>## Pseudo R^2 for logistic regression
## Hosmer and Lemeshow R^2  0.064 
## Cox and Shell R^2 0.084 
## Nagekkerke R^2 0.113</code></pre>
<pre class="r"><code>model.display &lt;- logistic.display(eelmodel_1)
model.table &lt;- model.display$table[rownames(model.display$table)!=&quot;&quot;, ]
kable(model.table, caption = model.display$first.line)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-19">Table 1: </span>
Logistic regression predicting Cured : Cured vs Not Cured</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OR(95%CI)</td>
<td align="left">3.42 (1.56,7.48)</td>
</tr>
<tr class="even">
<td>P(Wald’s test)</td>
<td align="left">0.002</td>
</tr>
<tr class="odd">
<td>P(LR-test)</td>
<td align="left">0.002</td>
</tr>
</tbody>
</table>
<ul>
<li><code>X = 0</code> 일때의 승산</li>
</ul>
<pre class="r"><code>p_cured &lt;- 1/(1 + exp(-(-.288 + 1.229*0)))
p_cured</code></pre>
<pre><code>## [1] 0.4284936</code></pre>
<pre class="r"><code>p_not_cured &lt;- 1 - p_cured
p_not_cured</code></pre>
<pre><code>## [1] 0.5715064</code></pre>
<pre class="r"><code>odds &lt;- p_cured/p_not_cured
odds</code></pre>
<pre><code>## [1] 0.7497616</code></pre>
<ul>
<li><code>X = 1</code> 일때의 승산</li>
</ul>
<pre class="r"><code>p_cured_1 &lt;- 1/(1 + exp(-(-.288 + 1.229*1))); p_cured_1</code></pre>
<pre><code>## [1] 0.7193016</code></pre>
<pre class="r"><code>p_not_cured_1 &lt;- 1 - p_cured_1; p_not_cured_1</code></pre>
<pre><code>## [1] 0.2806984</code></pre>
<pre class="r"><code>odds_1 &lt;- p_cured_1 / p_not_cured_1; odds_1</code></pre>
<pre><code>## [1] 2.562543</code></pre>
<ul>
<li>이렇게 예측변수의 1단위 변경 이전(<code>odds</code>)과 이후(<code>odds_1</code>)의 승산들이 나왔다. 이제 예측변수의 1단위 변경 이후의 승산을 이전의 승산으로 나누어 승산비를 구한다.</li>
</ul>
<pre class="r"><code>odds_ratio &lt;- odds_1/odds; odds_ratio # exp(1.2287) 의 값이 3.41781임에 유의</code></pre>
<pre><code>## [1] 3.41781</code></pre>
<p>또한, 예측변수의 b 계수의 지수함수로서의 승산비도 계산해보자.</p>
<pre class="r"><code>eelmodel_1$coefficients %&gt;% exp()</code></pre>
<pre><code>##              (Intercept) InterventionIntervention 
##                 0.750000                 3.416667</code></pre>
<p> 위에서 직접 계산한 승산비와 이 값은 서로 동일하다(반올림을 고려할 때). 이 값이 1보다 크다는 것은 예측변수가 증가하면 결과가 발생할 승산도 증가한다는 뜻이다.반대로 1보다 작으면 결과가 발생할 승산이 감소한다는 뜻이다.</p>
<p> 이 예에서는 처치를 받은 환자가 치료될 승산이 처치를 받지 않은 환자가 치료될 승산의 3.42배라고 말할 수 있다.</p>
<p> 승산비들의 신뢰구간을 구해보자.</p>
<pre class="r"><code>exp(confint(eelmodel_1))</code></pre>
<pre><code>##                              2.5 %   97.5 %
## (Intercept)              0.4374531 1.268674
## InterventionIntervention 1.5820127 7.625545</code></pre>
<p> 이 결과에서 중요한 것은 예측변수 승산비의 신뢰구간에 1이 포함되지 않는다는 점이다. 신뢰구간의 상계와 하계가 모두 1보다 크므로 모집단에서의 관계의 방향이 관측된 관계의 방향과 같다고 확신할 수 있다.(하계가 1보다 작다면 확신할 수 없다.)</p>
</div>
<div id="모형2-intervention과-duration-변수로-예측" class="section level3">
<h3>8.6.6 모형2: Intervention과 Duration 변수로 예측</h3>
<pre class="r"><code>eelmodel_2 %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## glm(formula = Cured ~ Intervention + Duration, family = binomial(), 
##     data = eelData)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6025  -1.0572   0.8107   0.8161   1.3095  
## 
## Coefficients:
##                           Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)              -0.234660   1.220563  -0.192  0.84754   
## InterventionIntervention  1.233532   0.414565   2.975  0.00293 **
## Duration                 -0.007835   0.175913  -0.045  0.96447   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 154.08  on 112  degrees of freedom
## Residual deviance: 144.16  on 110  degrees of freedom
## AIC: 150.16
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p> Duration의 b값은 꽤 작은 값인 -0.007835이고 확률은 .964로 &gt; .05이므로 유의하지 않다.</p>
<p> 모형 1과 모형 2를 비교해 보면, 두 모형의 이탈도가 같다.(144.16) 이는 모형 2가 모형 1보다 그리 크게 개선되지는 않았음을 뜻한다.</p>
<p> <code>anova()</code> 함수를 이용해 모형들의 차이를 계산해보자. <code>anova()</code> 함수는 자유도는 계산해주지만 유의확률까지 계산해 주지는 않는다.</p>
<pre class="r"><code>anova(eelmodel_1, eelmodel_2)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Cured ~ Intervention
## Model 2: Cured ~ Intervention + Duration
##   Resid. Df Resid. Dev Df  Deviance
## 1       111     144.16             
## 2       110     144.16  1 0.0019835</code></pre>
<p> 두 모형의 이탈도 차이, 자유도 차이 및 유의확률을 직접 계산을 통해 구해보자.</p>
<pre class="r"><code>modelChi &lt;- eelmodel_1$deviance - eelmodel_2$deviance
chidf &lt;- eelmodel_1$df.residual - eelmodel_2$df.residual
chisq.prob &lt;- 1 - pchisq(modelChi, chidf)

modelChi; chidf; chisq.prob</code></pre>
<pre><code>## [1] 0.001983528</code></pre>
<pre><code>## [1] 1</code></pre>
<pre><code>## [1] 0.9644765</code></pre>
<p> 두 모형의 이탈도 차이는 0.001983528이고 자유도 차이는 1이다. p 값은 0.9644765인데 &gt;.05이므로 유의하지 않다.</p>
</div>
<div id="핵심정리" class="section level3">
<h3>핵심정리</h3>
<ul>
<li><p>최종 모형의 전반적인 적합도는 이탈도 통계량과 그와 연관된 카이제곱 통계량으로 평가할 수 있다. 카이제곱 통계량의 유의확률이 .05보다 작으면 그 모형은 자료에 유의한 수준으로 잘 적합하는 것이다.</p></li>
<li><p>승산비를 통해 모델을 해석한다. <code>exp(model$coefficients)</code> 형태의 명령으로 구할 수 있다. 승산비가 1보다 크다는 것은 예측변수가 증가하면 결과가 발생할 승산도 증가한다는 뜻이다. 반대로, 승산비가 1보다 작다는 것은 예측변수가 증가하면 결과가 발생할 승산이 감소한다는 것이다. 이러한 해석에 신뢰성이 있으려면 승산비의 신뢰구간에 1이 포함되어서는 안 된다.</p></li>
</ul>
</div>
<div id="로지스틱-회귀의-사례별-진단" class="section level3">
<h3>로지스틱 회귀의 사례별 진단</h3>
<div id="잔차-구하기" class="section level4">
<h4>잔차 구하기</h4>
<p> <code>resid()</code> 함수를 이용해 로지스틱 회귀 모델의 잔차를 구한다.</p>
<p> <code>fitted()</code> 함수를 이용해 로지스틱 회귀의 적합값을 구한다. 이 적합값은 선형회귀의 값과 의미가 다른데, 각 예측변수 값이 주어졌을 때 해당 Y값이 발생할 확률을 예측한 값이다.</p>
<p><span class="math display">\[P(Y) = \frac{1}{1 + exp(-(b_{0} + b_{1}X_{1i} + b_{2}X_{2i} + ... + b_{n}X_{n}))}\]</span></p>
<p> 또한, 예측된 그룹 소속도(predicted group membership)를 회귀모형과 각 참가자에 대한 가장 가능도 높은 결과에 기초해서 계산할 수도 있다.</p>
<p> 이 값들을 담은 변수들을 데이터 데이터프레임에 추가하고 여러 검정을 수행할 수 있다.</p>
<pre class="r"><code>eelData$predicted.prob &lt;- fitted(eelmodel_1)
eelData$standized.residuals &lt;- rstandard(eelmodel_1)
eelData$studentized.residuals &lt;- rstudent(eelmodel_1)
# eelData$dfbeta &lt;- dfbeta(eelmodel_1)
eelData$diffit &lt;- dffits(eelmodel_1)
eelData$leverage &lt;- hatvalues(eelmodel_1)</code></pre>
</div>
<div id="예측된-확률" class="section level4">
<h4>예측된 확률</h4>
<pre class="r"><code>eelData %&gt;%
  as_tibble() %&gt;%
  select(Cured, Intervention, Duration, predicted.prob) </code></pre>
<pre><code>## # A tibble: 113 x 4
##    Cured     Intervention Duration predicted.prob
##    &lt;fct&gt;     &lt;fct&gt;           &lt;int&gt;          &lt;dbl&gt;
##  1 Not Cured No Treatment        7          0.429
##  2 Not Cured No Treatment        7          0.429
##  3 Not Cured No Treatment        6          0.429
##  4 Cured     No Treatment        8          0.429
##  5 Cured     Intervention        7          0.719
##  6 Cured     No Treatment        6          0.429
##  7 Not Cured Intervention        7          0.719
##  8 Cured     Intervention        7          0.719
##  9 Cured     No Treatment        8          0.429
## 10 Not Cured No Treatment        7          0.429
## # ... with 103 more rows</code></pre>
<p> 현재 치료에 대한 유의미한 변수는 <code>Intervention</code> 뿐이다.</p>
<p> 위의 표를 살펴보면, 환자가 처치를 받지 않았을 때(No Treatment, Intervention = 0) 치료될 확률은 .429이다. 약 43%가 치료된다. 그러나 개입이 있었다면 환자가 치료될 확률은 .719이다.</p>
</div>
<div id="잔차의-해석" class="section level4">
<h4>잔차의 해석</h4>
<p> 이 모형이 정말로 좋은 모형인지 확인하려면 잔차들을 조사해야 한다. 그 이유는 다음과 같다.
- 모형이 잘 적합하지 않는 자료점들을 격리
- 모형에 필요 이상으로 큰 영향을 주는 자료점들을 격리</p>
<pre class="r"><code>eelData %&gt;%
  select(leverage, studentized.residuals)</code></pre>
<pre><code>##       leverage studentized.residuals
## 1   0.01785714            -1.0643627
## 2   0.01785714            -1.0643627
## 3   0.01785714            -1.0643627
## 4   0.01785714             1.3110447
## 5   0.01754386             0.8160435
## 6   0.01785714             1.3110447
## 7   0.01754386            -1.6083171
## 8   0.01754386             0.8160435
## 9   0.01785714             1.3110447
## 10  0.01785714            -1.0643627
## 11  0.01754386             0.8160435
## 12  0.01785714             1.3110447
## 13  0.01785714             1.3110447
## 14  0.01754386            -1.6083171
## 15  0.01785714            -1.0643627
## 16  0.01785714            -1.0643627
## 17  0.01754386             0.8160435
## 18  0.01754386            -1.6083171
## 19  0.01754386             0.8160435
## 20  0.01754386             0.8160435
## 21  0.01785714            -1.0643627
## 22  0.01754386             0.8160435
## 23  0.01754386             0.8160435
## 24  0.01785714            -1.0643627
## 25  0.01754386             0.8160435
## 26  0.01754386             0.8160435
## 27  0.01785714             1.3110447
## 28  0.01785714             1.3110447
## 29  0.01754386             0.8160435
## 30  0.01754386             0.8160435
## 31  0.01785714            -1.0643627
## 32  0.01785714             1.3110447
## 33  0.01754386             0.8160435
## 34  0.01754386            -1.6083171
## 35  0.01754386             0.8160435
## 36  0.01785714             1.3110447
## 37  0.01785714             1.3110447
## 38  0.01754386            -1.6083171
## 39  0.01785714             1.3110447
## 40  0.01754386             0.8160435
## 41  0.01785714             1.3110447
## 42  0.01754386            -1.6083171
## 43  0.01754386             0.8160435
## 44  0.01754386            -1.6083171
## 45  0.01785714            -1.0643627
## 46  0.01785714            -1.0643627
## 47  0.01785714            -1.0643627
## 48  0.01754386            -1.6083171
## 49  0.01754386            -1.6083171
## 50  0.01785714             1.3110447
## 51  0.01754386             0.8160435
## 52  0.01754386             0.8160435
## 53  0.01754386             0.8160435
## 54  0.01785714             1.3110447
## 55  0.01785714            -1.0643627
## 56  0.01754386             0.8160435
## 57  0.01754386             0.8160435
## 58  0.01785714            -1.0643627
## 59  0.01754386             0.8160435
## 60  0.01754386             0.8160435
## 61  0.01785714             1.3110447
## 62  0.01785714            -1.0643627
## 63  0.01785714             1.3110447
## 64  0.01754386            -1.6083171
## 65  0.01754386             0.8160435
## 66  0.01785714            -1.0643627
## 67  0.01785714            -1.0643627
## 68  0.01785714             1.3110447
## 69  0.01785714            -1.0643627
## 70  0.01785714            -1.0643627
## 71  0.01754386             0.8160435
## 72  0.01785714            -1.0643627
## 73  0.01754386            -1.6083171
## 74  0.01754386             0.8160435
## 75  0.01754386             0.8160435
## 76  0.01785714             1.3110447
## 77  0.01754386             0.8160435
## 78  0.01754386            -1.6083171
## 79  0.01785714             1.3110447
## 80  0.01754386            -1.6083171
## 81  0.01785714             1.3110447
## 82  0.01785714            -1.0643627
## 83  0.01754386             0.8160435
## 84  0.01754386             0.8160435
## 85  0.01754386            -1.6083171
## 86  0.01754386             0.8160435
## 87  0.01785714             1.3110447
## 88  0.01754386            -1.6083171
## 89  0.01754386             0.8160435
## 90  0.01785714            -1.0643627
## 91  0.01754386             0.8160435
## 92  0.01785714            -1.0643627
## 93  0.01754386             0.8160435
## 94  0.01754386             0.8160435
## 95  0.01754386            -1.6083171
## 96  0.01754386             0.8160435
## 97  0.01785714             1.3110447
## 98  0.01785714            -1.0643627
## 99  0.01785714            -1.0643627
## 100 0.01754386             0.8160435
## 101 0.01785714            -1.0643627
## 102 0.01785714            -1.0643627
## 103 0.01754386             0.8160435
## 104 0.01785714             1.3110447
## 105 0.01785714            -1.0643627
## 106 0.01785714             1.3110447
## 107 0.01785714            -1.0643627
## 108 0.01785714            -1.0643627
## 109 0.01754386             0.8160435
## 110 0.01754386             0.8160435
## 111 0.01785714            -1.0643627
## 112 0.01785714            -1.0643627
## 113 0.01754386             0.8160435</code></pre>
<pre class="r"><code>ggplot(eelData, aes(y = studentized.residuals)) +
  geom_boxplot() + 
  coord_flip()</code></pre>
<p><img src="/post/2020-04-21-Logistic_Regression_files/figure-html/unnamed-chunk-35-1.png" width="576" style="display: block; margin: auto;" /></p>
<p> 스튜던트화 잔차가 <span class="math inline">\(\pm2\)</span> 이내 이므로 괜찮다고 할 수 있다.</p>
<pre class="r"><code>ggplot(eelData, aes(y = leverage)) +
  geom_boxplot() + 
  coord_flip()</code></pre>
<p><img src="/post/2020-04-21-Logistic_Regression_files/figure-html/unnamed-chunk-36-1.png" width="576" style="display: block; margin: auto;" /></p>
<p> 지렛대 통계량이 계산된 기대값인 .018과 아주 가깝다.</p>
<p><span class="math display">\[\frac{k + 1}{N} = \frac{1 + 1}{113} = .018\]</span></p>
</div>
</div>
<div id="핵심정리-1" class="section level3">
<h3>핵심정리</h3>
<ul>
<li><p>표준화잔차들을 살펴보아서 절대값이 2보다 큰 사례들이 전체의 5%를 넘기지 않는지, 절댓값이 2.5보다 큰 사례들이 전체의 약 1%를 넘지는 않는지 확인한다. 절대값이 3보다 큰 사례는 이상치일 수 있다.</p></li>
<li><p>평균지렛대 값을 계산하고, 지렛대 값이 평균의 2배 또는 3배 이상인 사례들을 찾는다.</p></li>
<li><p>DFBeta의 절대값이 1보다 큰 사례들을</p></li>
</ul>
</div>
<div id="효과크기의-계산" class="section level3">
<h3>효과크기의 계산</h3>
<p> 승산비를 효과크기의 측도로 사용하면 된다.</p>
</div>
</div>
<div id="로지스틱-회귀분석-보고-방법" class="section level2">
<h2>로지스틱 회귀분석 보고 방법</h2>
<p> 가능한 결과를 표로 작성한다. 이 때 베타값들과 해당 표준오차 및 유의확률, 그리고 모형에 관한 몇 가지 일반적인 통계량(<span class="math inline">\(R^{2}\)</span>과 적합도 통계량) 등을 명시하도록 한다. 그 외 승산비들과 그 신뢰구간도 보고하도록 하자.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">B(SE)</th>
<th align="center">하계</th>
<th align="center">승산비</th>
<th align="center">상계</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">포함된 변수</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">상수</td>
<td align="center">-0.29 (.27)</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">개입</td>
<td align="center">1.23 (.40)</td>
<td align="center">1.56</td>
<td align="center">3.42</td>
<td align="center">7.48</td>
</tr>
</tbody>
</table>
<p>비고, <span class="math inline">\(R^{2} = .06\)</span> (호스머-렘쇼), .08 (콕스-스넬), .11(네이글커크). 모형 <span class="math inline">\(\chi^{2}(1) = 9.93, \ p &lt; .01 *\)</span></p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

