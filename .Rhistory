battle.inst.2_1 %>% head()
battle.inst.2_1 %>%
select(user_id) -> df.user_id
battle.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~  round(./total, 2))) -> battle.inst.prop
df.user_id %>%
bind_cols(battle.inst.prop) -> battle.inst.prop_1
battle.inst.prop_1
battle.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_battle.inst
pr_battle.inst$x %>% as_tibble() -> pr_battle.inst_1
df.user_id %>%
bind_cols(pr_battle.inst_1) -> pr_battle.inst_2
pr_battle.inst_2
message %>%
inner_join(install, by = 'user_id', suffix = c('', '.inst')) -> msg.inst
# 메세지 행동일과 이용시작일의 차이 즉 경과일수를 구합니다.
msg.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) -> msg.inst.1
# 경과일수가 1주 이내인 것만 추출합니다.
msg.inst.1 %>%
filter(elapsed_days >= 0 & elapsed_days <= 6) -> msg.inst.2
# 경과일수별 메세지 행동횟수가 열에 오도록 데이터를 배치합니다.
msg.inst.2 %>%
mutate(elapsed_days = paste0('d', as.character(elapsed_days))) %>%
select(user_id, count, elapsed_days) %>%
group_by(user_id, elapsed_days) %>%
summarise(sum.count = sum(count)) %>%
ungroup() %>%
spread(elapsed_days, sum.count) %>%
replace(is.na(.), 0) -> msg.inst.2_1
msg.inst.2_1 %>% head
# 비율 데이터를 작성합니다.
msg.inst.2_1 %>%
select(user_id) -> df.user_id
msg.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~round(./total, 2))) -> msg.inst.prop
df.user_id %>%
bind_cols(msg.inst.prop) -> msg.inst.prop_1
msg.inst.prop_1 %>% head
msg.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_msg.inst
pr_msg.inst$x %>% as_tibble() -> pr_msg.inst_1
df.user_id %>%
bind_cols(pr_msg.inst_1) -> pr_msg.inst_2
pr_msg.inst_2 %>% head
hlp %>%
inner_join(install, by = 'user_id', suffix = c('', '.inst')) -> hlp.inst
# 메세지 행동일과 이용시작일의 차이 즉 경과일수를 구합니다.
hlp.inst %>%
mutate(log_date = as.Date(log_date),
log_date.inst = as.Date(log_date.inst)) %>%
mutate(elapsed_days = as.numeric(log_date - log_date.inst)) -> hlp.inst.1
# 경과일수가 1주 이내인 것만 추출합니다.
hlp.inst.1 %>%
filter(elapsed_days >= 0 & elapsed_days <= 6) -> hlp.inst.2
# 경과일수별 메세지 행동횟수가 열에 오도록 데이터를 배치합니다.
hlp.inst.2 %>%
mutate(elapsed_days = paste0('d', as.character(elapsed_days))) %>%
select(user_id, count, elapsed_days) %>%
group_by(user_id, elapsed_days) %>%
summarise(sum.count = sum(count)) %>%
ungroup() %>%
spread(elapsed_days, sum.count) %>%
replace(is.na(.), 0) -> hlp.inst.2_1
hlp.inst.2_1 %>% head
# 비율 데이터를 작성합니다.
hlp.inst.2_1 %>%
select(user_id) -> df.user_id
hlp.inst.2_1 %>%
select(-user_id) %>%
mutate(total = rowSums(.)) %>%
mutate_if(is.numeric, list(~round(./total, 2))) -> hlp.inst.prop
df.user_id %>%
bind_cols(hlp.inst.prop) -> hlp.inst.prop_1
hlp.inst.prop_1 %>% head
hlp.inst.2_1 %>%
select(-user_id) %>%
prcomp(scale = T) -> pr_hlp.inst
pr_hlp.inst$x %>% as_tibble() -> pr_hlp.inst_1
df.user_id %>%
bind_cols(pr_hlp.inst_1) -> pr_hlp.inst_2
pr_hlp.inst_2 %>% head
library(foreach)
# 클러스터 데이터 작성 함수
createClusterData <- function(aname, x, x.prop, x.pca) {
set.seed(2019)
df <- ldply(foreach(i = 3:6, combine = rbind) %do% {
km <- kmeans(x[, -1], i)
km.prop <- kmeans(x.prop[, -1], i)
km.pca <- kmeans(x.pca[, -1], i)
data.frame(user_id = x$user_id,
cluster.type = sprintf('%s%02d', aname, i),
freq.cluster.id = km$cluster,
prop.cluster.id = km.prop$cluster,
pca.cluster.id = km.pca$cluster
)
})
cluster.melt <- melt(df, id.vars = c('user_id', 'cluster.type'))
dcast(cluster.melt, user_id ~ cluster.type + variable)
}
battle.cluster <- createClusterData('battle', battle.inst.2_1, battle.inst.prop_1, pr_battle.inst_2)
battle.cluster %>% head
msg.cluster <- createClusterData('msg', msg.inst.2_1, msg.inst.prop_1, pr_msg.inst_2)
msg.cluster %>% head
hlp.cluster <- createClusterData('hlp', hlp.inst.2_1, hlp.inst.prop_1, pr_hlp.inst_2)
hlp.cluster %>% head
target.install.login.ds %>%
left_join(battle.cluster, by = 'user_id') %>%
left_join(msg.cluster, by = 'user_id') %>%
left_join(hlp.cluster, by = 'user_id') %>%
replace(is.na(.), 0) -> cluster.data
cluster.data %>% head
cluster.data %>% head
cluster.data %>%
dplyr::select(-log_date, -install_time, -gender, -generation, -device_type) %>%
gather(variable, value, -user_id, -density) -> cluster.data.gathered
cluster.data.gathered %>% head
cluster.data.gathered %>%
group_by(variable, value) %>%
summarise(avg.density = mean(density)) -> cluster.data.avg
cluster.data.avg %>% head()
# 새로운 클러스터 번호  부여
cluster.data.avg %>%
arrange(variable, avg.density) %>%
group_by(variable) %>%
mutate(value2 = sort(value)) -> cluster.data.avg_1
cluster.data.avg_1 %>% head()
cluster.data.gathered %>%
inner_join(cluster.data.avg_1, by = c('variable', 'value')) -> cluster.data.gathered_1
cluster.data.gathered_1 %>%
select(user_id, density, variable, value2) %>%
spread(variable, value2) -> cluster.data_1
cluster.data_1 %>% head()
library(rpart)
fit <- rpart(density ~ ., cluster.data_1[, -1])
print(fit)
library(rpart.plot)
rpart.plot(fit)
cluster.data.gathered_1 %>%
filter(variable == 'hlp04_pca.cluster.id') %>%
select(user_id, avg.density, value2) %>%
rename(cluster = value2) -> cluster.data_2
cluster.data_2 %>% head
hlp.inst.prop_1 %>%
inner_join(cluster.data_2, by = 'user_id') %>%
count(cluster)
library(rpart)
fit <- rpart(density ~ ., cluster.data_1[, -1])
print(fit)
cluster.data %>%
dplyr::select(-log_date, -install_time, -gender, -generation, -device_type) %>%
gather(variable, value, -user_id, -density) -> cluster.data.gathered
cluster.data.gathered %>% head
df_1 <- data.frame(start = c(60000, 34000000),
end = c(3300000, 67980000809))
df_1
df_2 <- data.frame(start = c(4000, 100000, 70000, 34000001),
end = c(200000, 599099, 900020, 460000000))
source('~/.active-rstudio-document', echo=TRUE)
df_2 %>%
rename(start_1 = start,
end_1  = end)
df_2 %>%
rename(start_1 = start,
end_1  = end) -> df)2
df_2 %>%
rename(start_1 = start,
end_1  = end) -> ddf_2
df_1 %>%
bind_cols(df_1)
df_1 %>%
bind_rows(df_1)
df_2 %>%
rename(start_1 = start,
end_1  = end) -> df_2_1
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1)
start <= start_1 & end >= end_1, "O", "X")
df_1 %>%
df_1 %>%
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
start <= start_1 & end >= end_1, "O", "X"))
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
(start <= start_1 & end >= end_1), "O", "X"))
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
(start <= start_1 & end >= end_1) ~ "O"
TRUE ~ "X"))
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
(start <= start_1 & end >= end_1) ~ "O",
TRUE ~ "X"))
df_1 %>%
bind_rows(df_1)  %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
start <= start_1 & end >= end_1 ~ "O",
TRUE ~ "X"))
library(tidyverse)
df_1 <- data.frame(start = c(60000, 34000000),
end = c(3300000, 67980000809))
df_2 <- data.frame(start = c(4000, 100000, 70000, 34000001),
end = c(200000, 599099, 900020, 460000000))
# 이름의 중복을 피하기 위해 변수병을 변환("_1"을 붙여봄)
df_2 %>%
rename(start_1 = start,
end_1  = end) -> df_2_1
# 각 행마다 해당하는 조건을 대응시키기 위해 두 데이터 프레임의 행의 수를 같게 함.
df_1 %>%
bind_rows(df_1) -> df_1_1
df_1_1 %>%
bind_cols(df_2_1) %>%
mutate(is_in_range = case_when(
start <= start_1 & end >= end_1 ~ "O",
TRUE ~ "X"))
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", message=F, warning=F, cache = T)
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
# install.packages('epiDisplay')
library(epiDisplay)
library(knitr)
# install.packages('mlogit')
library(mlogit)
library(plotly)
library(curl)
library(gridExtra)
library(GGally)
library(caret)
library(DT)
library(ROCR)
adult <- read_csv('https://raw.githubusercontent.com/jakinpilla/first_blogdown/master/public/post/data/adult_1.csv')
# adult <- read_csv('./data/adult_1.csv')
adult %>% glimpse()
model.matrix(~ . -wage, adult ) %>%
as_tibble() -> df_1
adult %>%
select(wage) %>%
bind_cols(df_1) %>%
select(-`(Intercept)`) -> adult_mm
adult_mm %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal()
set.seed(2020)
df <- adult_mm
train_idx <- createDataPartition(df$wage, p = .6, list = F)[, 1]
resid_idx <- setdiff(1:nrow(df), train_idx)
resid_df <- df[resid_idx, ]
val_idx <- createDataPartition(resid_df$wage, p = .5, list = F)[, 1]
test_idx <- setdiff(1:nrow(resid_df), val_idx)
train_data <- df[train_idx, ]
val_data <- resid_df[val_idx, ]
test_data <- resid_df[test_idx, ]
train_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal()
train_data %>% dim()
val_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal()
test_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal()
test_data %>% dim()
train_data %>%
mutate(wage = ifelse(wage == "<=50K", 0, 1)) -> train_data_1
df <- train_data_1 %>% head(100)
DT::datatable(df,
options = list(
scrollX = TRUE,
scrollCollapse = TRUE
))
adult_logistic_m <- glm(wage ~ ., data = train_data_1, family = binomial)
# summary(adult_logistic_m)
y_obs <- ifelse(val_data$wage == "<=50K", 0, 1)
# val_data를 predict() 함수에 넣기 전에 다음과 같은 전처리가 필요합니다. wage 변수를 예측하려는데
# wage 변수가 들어가 있는 데이터를 사용하면 안 되기 때문입니다.
val_data %>%
select(-wage) -> val_data_1
yhat_logistic <- predict(adult_logistic_m, newdata = val_data_1, type = 'response')
pred_logistic <- prediction(yhat_logistic, y_obs)
perf_logistic <- performance(pred_logistic, measure = "tpr", x.measure = "fpr")
df_logistic <- data.frame(FPR = perf_logistic@x.values[[1]], TPR = perf_logistic@y.values[[1]]) %>%
as_tibble()
df_logistic %>% ggplot(aes(x = FPR, y = TPR)) +
geom_line(color = 'blue') +
geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1)) +
ggtitle('ROC Curve') +
labs(x = 'False Positive Rate', y = 'True Positive Rate') +
theme_minimal() -> p; p
performance(pred_logistic, "auc")@y.values[[1]]
yhat_logistic
predict(adult_logistic_m, newdata = val_data_1[1:10, ], type = 'type')
predict(adult_logistic_m, newdata = val_data_1[1:10, ], type = 'link')
predict(adult_logistic_m, newdata = val_data_1[1:10, ], type = 'terms')
adult_logistic_m <- glm(wage ~ ., data = train_data_1, family = 'binomial')
y_obs <- ifelse(val_data$wage == "<=50K", 0, 1)
# val_data를 predict() 함수에 넣기 전에 다음과 같은 전처리가 필요합니다. wage 변수를 예측하려는데
# wage 변수가 들어가 있는 데이터를 사용하면 안 되기 때문입니다.
val_data %>%
select(-wage) -> val_data_1
yhat_logistic <- predict(adult_logistic_m, newdata = val_data_1, type = 'response')
blogdown:::serve_site()
setwd("~/first_blogdown")
blogdown:::serve_site()
blogdown:::serve_site()
install.packages("rmarkdown")
install.packages("blogdown")
install.packages("tidyverse")
install.packages("GGally")
install.packages("ez")
install.packages("nlme")
install.packages("pastecs")
install.packages("reshape2")
install.packages("WRS")
install.packages("clinfun")
install.packages("pgirmess")
install.packages("car")
install.packages("mvoutlier")
install.packages("gmodels")
install.packages("MASS")
install.packages("QuantPsyc")
install.packages("epiDisplay")
install.packages("knitr")
install.packages("mlogit")
install.packages("plotly")
installed.packages("curl")
install.packages("gridExtra")
install.packages("caret")
install.packages("DT")
install.packages("ROCR")
install.packages(c("caret", "clinfun", "DT", "epiDisplay", "gmodels", "gridExtra", "mlogit", "mvoutlier", "pgirmess", "plotly", "QuantPsyc", "ROCR"))
install.packages("shiny")
install.packages("miniUI")
blogdown:::serve_site()
install.packages("akima")
blogdown:::serve_site()
# first: install dependent packages
install.packages(c("MASS", "akima", "robustbase"))
# second: install suggested packages
install.packages(c("cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "parallel", "mc2d", "psych", "Rfit"))
# third: install WRS
install.packages("WRS", repos="http://R-Forge.R-project.org", type="source")
blogdown:::serve_site()
library(htmlwidgets)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", message=F, warning=F, cache=T, fig.width = 6, fig.height = 4)
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
# library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
# install.packages('epiDisplay')
library(epiDisplay)
library(knitr)
# install.packages('mlogit')
library(mlogit)
library(plotly)
myfun <- function(x_var) {1 / (1 + exp(-x_var))};
ggplot(data.frame(x= c(-10, 10)), aes(x=x)) +
stat_function(fun = myfun, geom="line", size = 1.2, color = 'steelblue') +
xlab("Z") +
ylab("P(Y)") +
theme_minimal() -> p1; ggplotly(p1)
myfun_1 <- function(mu_var) {mu_var / (1 - mu_var)};
ggplot(data.frame(x= c(0, 1)), aes(x=x)) +
stat_function(fun = myfun_1, geom="line", size = 1.2, color = 'steelblue') +
xlab("mu") +
ylab(paste("odds")) +
theme_minimal() -> p_2; ggplotly(p_2)
myfun_2 <- function(mu_var) {log(mu_var / (1 - mu_var))};
ggplot(data.frame(x= c(0, 1)), aes(x=x)) +
stat_function(fun = myfun_2, geom="line", size = 1.2, color = 'steelblue') +
labs(x = "mu", y = "Y") +
theme_minimal() -> p_3; ggplotly(p_3)
myfun_2 <- function(mu_var) {log(mu_var / (1 - mu_var))};
ggplot(data.frame(x= c(0, 1)), aes(x=x)) +
stat_function(fun = myfun_2, geom="line", size = 1.2, color = 'steelblue') +
labs(x = "mu", y = "Y") +
theme_minimal() -> p_3; ggplotly(p_3)
blogdown:::serve_site()
unlink('content/post/2020-04-21-Logistic_Regression_cache', recursive = TRUE)
blogdown:::serve_site()
unlink('content/post/2020-04-21-Logistic_Regression_cache', recursive = TRUE)
unlink('content/post/2020-04-23-Logistic_Regression_Evaluation_LL_cache', recursive = TRUE)
unlink('content/post/2020-04-27-Adult_Census_Data_EDA_1_cache', recursive = TRUE)
unlink('content/post/2020-04-30-Adult_Census_Data_EDA_2_cache', recursive = TRUE)
unlink('content/post/2020-04-30-Logistic_Regression_Example_with_Adult_Dataset_cache', recursive = TRUE)
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", message=F, warning=F)
# wage 변수는 목적변수이므로 model.matrix() 함수를 적용할 땐 제외합니다.
model.matrix(~ . -wage, adult ) %>%
as_tibble() -> df_1 # matrix 자료형을 tibble() 형으로 변환합니다.
library(ez)
library(ggplot2)
library(nlme)
library(pastecs)
library(reshape2)
# library(WRS)
library(clinfun)
library(pgirmess)
library(car)
library(tidyverse)
# install.packages('mvoutlier')
library(mvoutlier)
library(gmodels)
library(MASS)
library(nlme) # 다층모형을 위해
library(QuantPsyc)
library(boot)
# install.packages('epiDisplay')
library(epiDisplay)
library(knitr)
# install.packages('mlogit')
library(mlogit)
library(plotly)
library(curl)
library(gridExtra)
library(GGally)
library(caret)
library(DT)
library(ROCR)
# wage 변수는 목적변수이므로 model.matrix() 함수를 적용할 땐 제외합니다.
model.matrix(~ . -wage, adult ) %>%
as_tibble() -> df_1 # matrix 자료형을 tibble() 형으로 변환합니다.
adult %>%
select(wage) %>% # 목적변수만 선택합니다.
bind_cols(df_1) %>%  # 위에서 생성한 데이터를 결합합니다.
select(-`(Intercept)`) -> adult_mm # 위에서 생성한 데이터 컬럼 중 (Intercept) 컬럼은 제외합니다.
adult_mm
adult_mm %>% dim()
adult_mm %>% colnames()
76-36+1
adult_mm %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal() -> p ; ggplotly(p)
train_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal()-> p1
test_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal() -> p3
grid.arrange(p1, p2, p3, ncol = 3)
val_data %>%
count(wage) %>%
ggplot(aes(wage, n, fill = wage)) + geom_bar(stat = 'identity') +
scale_fill_manual(values = c('steelblue', 'red'), aesthetics = 'fill') +
theme_minimal() -> p2
grid.arrange(p1, p2, p3, ncol = 3)
